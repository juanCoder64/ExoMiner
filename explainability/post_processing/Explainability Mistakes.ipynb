{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f199fd1c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-21T12:06:03.812337Z",
     "end_time": "2023-04-21T12:06:05.068548Z"
    }
   },
   "outputs": [],
   "source": [
    "# 3rd party\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bfa1d4f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-21T12:14:25.068157Z",
     "end_time": "2023-04-21T12:14:25.071855Z"
    }
   },
   "outputs": [],
   "source": [
    "def concat_csv(root_dir, num_PCs, trials, stat_func, branches):\n",
    "    \"\"\" Compute aggregated statistics first across representative PCs and then across trials.\n",
    "\n",
    "    :param root_dir: Path, root directory for all the experiments\n",
    "    :param num_PCs: int, number of representative PCs used\n",
    "    :param trials: int, number of trials performed\n",
    "    :param stat_func: func, statistic used to aggregate results from different trials\n",
    "    :param branches: list, list of branches (str) names to consider\n",
    "\n",
    "    :return: tuple, (train, val, test) statistics\n",
    "    \"\"\"\n",
    "\n",
    "    # run='/nobackup/khauskne/kdd/explainability_runs/exp_'+str(num_PCs)+'_PCs_trial'\n",
    "    run = root_dir / f'exp_{num_PCs}_PCs_trial'\n",
    "\n",
    "    for trial in range(1, trials+1):  # iterate through each trial and get scores for each data set for all number of representative PCs used\n",
    "\n",
    "        run_trial = f'{run}_{trial}/'  # get path to trial run\n",
    "\n",
    "        # get scores for each data set\n",
    "        all_train_groups=[]\n",
    "        for index in range(num_PCs):\n",
    "            train_group=pd.read_csv(run_trial+'train_top_'+str(index)+'.csv')\n",
    "            all_train_groups.append(train_group)\n",
    "\n",
    "        all_val_groups=[]\n",
    "        for index in range(num_PCs):\n",
    "            val_group=pd.read_csv(run_trial+'val_top_'+str(index)+'.csv')\n",
    "            all_val_groups.append(val_group)\n",
    "\n",
    "        all_test_groups=[]\n",
    "        for index in range(num_PCs):\n",
    "            test_group=pd.read_csv(run_trial+'test_top_'+str(index)+'.csv')\n",
    "            all_test_groups.append(test_group)\n",
    "\n",
    "        # compute mean and minimum score statistics for each branch across num_PCs in a trial run for each data set\n",
    "        train_statistics=apply_statistics(branches, all_train_groups, num_PCs)\n",
    "        val_statistics=apply_statistics(branches, all_val_groups, num_PCs)\n",
    "        test_statistics=apply_statistics(branches, all_test_groups, num_PCs)\n",
    "\n",
    "    print(f'Shape of train_statistics: {train_statistics.shape}')\n",
    "    print(train_statistics.head())\n",
    "    # compute aggregated statistics across trials using the stat_func\n",
    "    return stat_func(train_statistics, branches),  stat_func(val_statistics, branches), stat_func(test_statistics, branches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3badecc",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-21T12:07:37.574600Z",
     "end_time": "2023-04-21T12:07:37.576560Z"
    }
   },
   "outputs": [],
   "source": [
    "def apply_statistics(branches, files, num_PCs):\n",
    "    \"\"\" Compute mean and minimum scores across `num_PCs` results for each branch for a given data set and trial run.\n",
    "\n",
    "    :param branches: list, groupings of features\n",
    "    :param files: list, list of DataFrames that contain the scores for the different data sets (train, val, and test) [n_examples x (n_branches + other info cols)]\n",
    "    :param num_PCs: int, number of representative PCs used\n",
    "\n",
    "    :return: pandas DataFrame, mean and minimum scores across num_PCs for each branch for a given data set and trial run [n_examples x (n_branches + other info cols)]\n",
    "    \"\"\"\n",
    "\n",
    "    new_csv=files[0].copy()\n",
    "    new_csv.pop('Unnamed: 0')\n",
    "\n",
    "    for branch in branches:  # iterate over the branches\n",
    "\n",
    "        all_scores=np.zeros(tuple((num_PCs, np.shape(files[0])[0])))\n",
    "\n",
    "        for example in range(len(files)):  # iterate over num PCs\n",
    "            all_scores[example]=files[example][branch]\n",
    "\n",
    "        col_index=new_csv.columns.get_loc(branch)\n",
    "\n",
    "        # get mean across num PCs for a given branch\n",
    "        new_csv[branch]=np.mean(all_scores, axis=0)\n",
    "        # add minimum value\n",
    "        new_csv.insert(col_index+1, branch+' Min', np.min(all_scores, axis=0))\n",
    "\n",
    "    return new_csv\n",
    "\n",
    "\n",
    "def evaluate_mean(csv, branches):\n",
    "    \"\"\" Sets of features whose mean score decreased more than `threshold`.\n",
    "\n",
    "    :param csv: pandas DataFrame, mean and minimum scores across num_PCs for each branch for a given data set and trial run [n_examples x (n_branches + other info cols)]\n",
    "    :param branches: list, groupings of features\n",
    "\n",
    "    :return: dict,\n",
    "    \"\"\"\n",
    "\n",
    "    reduced_csv=csv\n",
    "    branch_explanation=np.zeros([len(branches), len(csv)])\n",
    "\n",
    "    for i in range(len(branches)):\n",
    "        branch_explanation[i]=(reduced_csv[branches[i]]<-0.5)\n",
    "    branch_explanation=np.moveaxis(branch_explanation, 0, -1)\n",
    "    \n",
    "    mean_dict={'target_id': csv['target_id'], 'tce_plnt_num': csv['tce_plnt_num'], 'original_label':csv['original_label'],\n",
    "              'full_score': csv['full score'], 'branch_explanations': branch_explanation}\n",
    "\n",
    "    return mean_dict\n",
    "\n",
    "def evaluate_min(csv, branches):\n",
    "\n",
    "    reduced_csv=csv\n",
    "\n",
    "    branch_explanation=np.zeros([len(branches), len(csv)])\n",
    "    for i in range(len(branches)):\n",
    "        branch_explanation[i]=(reduced_csv[branches[i]+ ' Min']<-0.5)\n",
    "    branch_explanation=np.moveaxis(branch_explanation, 0, -1)\n",
    "    \n",
    "    mean_dict={'target_id': csv['target_id'], 'tce_plnt_num': csv['tce_plnt_num'], 'original_label':csv['original_label'],\n",
    "              'full_score': csv['full score'], 'branch_explanations': branch_explanation}\n",
    "\n",
    "    return mean_dict\n",
    "\n",
    "def evaluate_max(csv, branches):\n",
    "\n",
    "    reduced_csv=csv\n",
    "\n",
    "    branch_explanation=np.zeros([len(branches), len(csv)])\n",
    "    for i in range(len(branches)):\n",
    "        branch_explanation[i]=(reduced_csv[branches[i]+ ' Max']<-0.5)\n",
    "    branch_explanation=np.moveaxis(branch_explanation, 0, -1)\n",
    "    \n",
    "    mean_dict={'target_id': csv['target_id'], 'tce_plnt_num': csv['tce_plnt_num'], 'original_label':csv['original_label'],\n",
    "              'full_score': csv['full score'], 'branch_explanations': branch_explanation}\n",
    "\n",
    "    return mean_dict\n",
    "\n",
    "def evaluate_med(csv, branches):\n",
    "\n",
    "    reduced_csv=csv\n",
    "\n",
    "    branch_explanation=np.zeros([len(branches), len(csv)])\n",
    "    for i in range(len(branches)):\n",
    "        branch_explanation[i]=(reduced_csv[branches[i]+ ' Med']<-0.5)\n",
    "    branch_explanation=np.moveaxis(branch_explanation, 0, -1)\n",
    "    \n",
    "    mean_dict={'target_id': csv['target_id'], 'tce_plnt_num': csv['tce_plnt_num'], 'original_label':csv['original_label'],\n",
    "              'full_score': csv['full score'], 'branch_explanations': branch_explanation}\n",
    "\n",
    "    return mean_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d63d44f3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-21T12:07:41.314789Z",
     "end_time": "2023-04-21T12:07:41.321509Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_unexplained_FPs(dictionary):\n",
    "    \"\"\" Find model FPs that have zero flags set (i.e., not explained). Model FPs are defined by examples with a full model score classification lower than threshold.\n",
    "\n",
    "    Args:\n",
    "        dictionary: dict, ids and branch explanations for each example\n",
    "\n",
    "    Returns:\n",
    "        unexplained_fps, dict with ids of model FPs that are not explained\n",
    "    \"\"\"\n",
    "    \n",
    "    ind_of_fp=np.where(dictionary['full_score']<0.5)[0]  # find examples for which the model classifies as FP according to the threshold\n",
    "    # count number of branches that are flagged for each model FP\n",
    "    num_of_contributing_branches_fp=np.sum(dictionary['branch_explanations'][ind_of_fp], axis=1)\n",
    "    # find examples that have zero branches flagged (i.e., model FPs not  explained)\n",
    "    inds=np.where(num_of_contributing_branches_fp==0)[0]\n",
    "    # get their ids\n",
    "    unexplained_fps=(np.array(dictionary['target_id'][ind_of_fp])[inds], np.array(dictionary['tce_plnt_num'][ind_of_fp])[inds])\n",
    "    \n",
    "    return unexplained_fps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74a97766",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-21T12:07:42.229107Z",
     "end_time": "2023-04-21T12:07:42.234432Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_explained_PCs(dictionary):\n",
    "    \"\"\" Find model PCs that have at least one flag set (i.e., explained). Model PCs are defined by examples with a full model score classification higher than threshold.\n",
    "\n",
    "    Args:\n",
    "        dictionary: dict, ids and branch explanations for each example\n",
    "\n",
    "    Returns:\n",
    "        explained_PCs, dict with ids of model PCs that are explained\n",
    "    \"\"\"\n",
    "\n",
    "    # count number of branches that are flagged for each example\n",
    "    num_of_contributing_branches_total=np.sum(dictionary['branch_explanations'], axis=1)\n",
    "    # find examples that have at least one branch flagged\n",
    "    ind_of_explained=np.where(num_of_contributing_branches_total>0)[0]\n",
    "    # num_of_explained=np.shape(ind_of_explained)[0]\n",
    "    inds_of_PCs=np.where(dictionary['full_score'][ind_of_explained]>0.5)[0]\n",
    "\n",
    "    explained_PCs=(np.array(dictionary['target_id'][inds_of_PCs]), np.array(dictionary['tce_plnt_num'][inds_of_PCs]))\n",
    "    \n",
    "    return explained_PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9b55dbe",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-21T13:48:00.395514Z",
     "end_time": "2023-04-21T13:48:03.109665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for trial run 1...\n",
      "Shape of train_statistics: (24745, 21)\n",
      "   target_id  tce_plnt_num  label  tce_period  tce_duration original_label  \\\n",
      "0    7767426             1      0    2.963930      0.610833            NTP   \n",
      "1    6945500             8      0   56.654701      0.220458            NTP   \n",
      "2    7429392             1      0  431.785004      0.234958            NTP   \n",
      "3   10490558             1      0    4.042710      0.430000            NTP   \n",
      "4    9836149             1      1   17.815901      0.158042             PC   \n",
      "\n",
      "     full score  Global Flux  Global Flux Min  Local Flux  ...  Centroid  \\\n",
      "0  1.874893e-07    -0.963458        -0.996854   -0.235851  ... -0.034293   \n",
      "1  6.537885e-07    -0.220597        -0.477100   -0.888691  ...  0.000667   \n",
      "2  2.471929e-06     0.000409        -0.012792   -0.597130  ... -0.010724   \n",
      "3  1.001734e-06    -0.563445        -0.949332   -0.276655  ...  0.000441   \n",
      "4  9.971827e-01    -0.000403        -0.012855    0.004024  ...  0.001253   \n",
      "\n",
      "   Centroid Min  Odd Even  Odd Even Min  Secondary  Secondary Min   Stellar  \\\n",
      "0     -0.116565 -0.001402     -0.004617  -0.071261      -0.187545  0.002387   \n",
      "1     -0.002600 -0.193357     -0.436814  -0.630851      -0.889469 -0.158445   \n",
      "2     -0.036133 -0.052186     -0.143314  -0.719142      -0.912823 -0.004408   \n",
      "3     -0.004092 -0.000078     -0.001866  -0.970399      -0.992015 -0.029012   \n",
      "4     -0.003149  0.000718     -0.000932   0.000689      -0.000138 -0.004099   \n",
      "\n",
      "   Stellar Min        DV    DV Min  \n",
      "0    -0.000146 -0.181227 -0.454931  \n",
      "1    -0.375584 -0.153871 -0.380433  \n",
      "2    -0.021769 -0.560692 -0.773252  \n",
      "3    -0.085406 -0.105427 -0.282416  \n",
      "4    -0.026346 -0.008159 -0.039163  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Running for trial run 2...\n",
      "Shape of train_statistics: (24745, 21)\n",
      "   target_id  tce_plnt_num  label  tce_period  tce_duration original_label  \\\n",
      "0    7767426             1      0    2.963930      0.610833            NTP   \n",
      "1    6945500             8      0   56.654701      0.220458            NTP   \n",
      "2    7429392             1      0  431.785004      0.234958            NTP   \n",
      "3   10490558             1      0    4.042710      0.430000            NTP   \n",
      "4    9836149             1      1   17.815901      0.158042             PC   \n",
      "\n",
      "     full score  Global Flux  Global Flux Min  Local Flux  ...  Centroid  \\\n",
      "0  1.874893e-07    -0.932902        -0.996918   -0.169061  ... -0.018537   \n",
      "1  6.537885e-07    -0.249837        -0.511205   -0.813086  ...  0.000251   \n",
      "2  2.471929e-06    -0.003079        -0.018699   -0.475162  ... -0.006201   \n",
      "3  1.001734e-06    -0.536586        -0.965375   -0.193592  ...  0.000293   \n",
      "4  9.971827e-01    -0.003127        -0.019242    0.001777  ...  0.001093   \n",
      "\n",
      "   Centroid Min  Odd Even  Odd Even Min  Secondary  Secondary Min   Stellar  \\\n",
      "0     -0.043263 -0.001077     -0.004716  -0.040864      -0.180995  0.001041   \n",
      "1     -0.003091 -0.142820     -0.370116  -0.544277      -0.745752 -0.103384   \n",
      "2     -0.030403 -0.027903     -0.110211  -0.638720      -0.841190 -0.004251   \n",
      "3     -0.002440 -0.000058     -0.002708  -0.946739      -0.993196 -0.020397   \n",
      "4     -0.000147  0.000152     -0.002459   0.000401      -0.000191 -0.003886   \n",
      "\n",
      "   Stellar Min        DV    DV Min  \n",
      "0    -0.001314 -0.117442 -0.346971  \n",
      "1    -0.222493 -0.079864 -0.242053  \n",
      "2    -0.016324 -0.459918 -0.745862  \n",
      "3    -0.079288 -0.063429 -0.183402  \n",
      "4    -0.012220 -0.001179 -0.004746  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "root_dir = Path('/Users/msaragoc/Library/CloudStorage/OneDrive-NASA/Projects/exoplanet_transit_classification/interns/kaylie_explainability/kdd/explainability_runs')\n",
    "branches=['Global Flux', 'Local Flux', 'Centroid', 'Odd Even', 'Secondary', 'Stellar', 'DV']\n",
    "n_trials = 2  # 10\n",
    "n_pcs = 10\n",
    "ids=[]\n",
    "plnts=[]\n",
    "for i in range(1,n_trials + 1):  # iterate over trial runs\n",
    "    print(f'Running for trial run {i}...')\n",
    "    # choose num_PCs as 10 and aggregating metric across trials a min value\n",
    "    csvs=concat_csv(root_dir, n_pcs, i, evaluate_min, branches)\n",
    "\n",
    "    # test set\n",
    "    ids.append(find_unexplained_FPs(csvs[2])[0])\n",
    "    plnts.append(find_unexplained_FPs(csvs[2])[1])\n",
    "\n",
    "# ids=np.concatenate(ids)\n",
    "# plnts=np.concatenate(plnts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b1ed180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mistakes=np.moveaxis([ids[np.argsort(ids)], plnts[np.argsort(ids)]], -1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1c322a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_vals=np.unique(mistakes, axis=0, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f9322495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3246984,       1],\n",
       "       [5309353,       1],\n",
       "       [9777793,       1]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_vals[0][np.where(unique_vals[1]==9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3e1e2f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2708286,  3221310,  3246984,  3353679,  3429707,  3560301,\n",
       "         4357985,  4386607,  4845555,  5265699,  5299861,  5302881,\n",
       "         5309353,  5353738,  5524881,  5716330,  5881893,  5983410,\n",
       "         6289897,  6365321,  6367260,  6381309,  6386784,  6387819,\n",
       "         6425135,  6522242,  6780367,  6890040,  6963171,  7045685,\n",
       "         7465661,  7523340,  7708418,  7839814,  7955708,  7971540,\n",
       "         8381693,  8692983,  8823893,  9025557,  9216810,  9334893,\n",
       "         9777793,  9824928, 10135362, 10154994, 10221153, 10485250,\n",
       "        10614845, 10989859, 10990092, 11071278, 11358392, 11390941,\n",
       "        11494130, 11656840, 11673686, 11811140, 12217403, 12783196]),\n",
       " array([ 1,  1,  9,  1,  2,  3,  2,  7,  5,  5,  1,  2,  9,  1,  8,  4,  4,\n",
       "         3,  8,  8,  3,  5,  5,  1,  5,  5,  8,  5,  1,  1,  2,  4,  9,  5,\n",
       "         2, 17,  2,  9,  8,  5,  2,  6,  9,  3,  2,  4,  1,  2,  1,  4,  3,\n",
       "         1,  3,  2,  3,  1,  1,  8,  2,  4]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(ids[np.argsort(ids)], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9946fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs=concat_csv(15, 9, evaluate_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c884eacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 9777256, 10661976, 10717591, 11912932,  7599004, 11494130,\n",
       "         6292162,  8748659, 11071278,  6119608, 10000547,  7971540,\n",
       "        11390838,  7871315,  6115025, 10472112,  8108551,  7465661,\n",
       "         3560301,  8057693,  9824928,  3955026,  4274480,  8174821,\n",
       "        11501492, 11673686,  9216810, 11253627,  5299861, 11656840,\n",
       "        11442793,  6600515,  9138680,  5036761,  6685533, 11254601,\n",
       "         8939843, 10614845,  5982073, 11358392,  8544169,  6963171,\n",
       "         8023238,  8298725,  6387819,  3555678,  9142053,  3336476,\n",
       "         3120397,  8044016,  8175925, 10990092,  6367260, 11811140,\n",
       "         6381309,  7523340,  6369539,  4845555,  8264623, 11390941,\n",
       "         8702874,  6701459,  8885132,  6367260,  1435448,  7765677,\n",
       "        10154994,  9895004,  8240890,  9340460,  8160316, 10978737,\n",
       "        11082830,  5309353,  8950952, 10221153,  6890040, 10959320,\n",
       "         5473535,  7621172,  7708418,  7839814,  7819674,  7293769,\n",
       "         6425135, 10337859,  8106610,  7971540,  4845555,  9111849,\n",
       "         6225475,  6222079,  2452185,  3973549,  9518651,  9777793,\n",
       "         8692983, 10205598,  9025557,  3429707,  8684570,  8432151,\n",
       "         3644649, 11446422,  8164615,  8941279,  1435448,  8687209,\n",
       "        10555365,  3221310,  6289897,  7045685, 10920420,  8870286,\n",
       "         3547523,  7839814,  5617535,  6042031, 10989859, 10135362,\n",
       "         6516932,  9300285,  6665570,  8747619,  8230809, 10485250,\n",
       "         6463499,  8490980,  9754973, 11962541,  7971540, 11876098,\n",
       "         4386607,  9291368,  6678472,  6364195, 12783196, 12405425,\n",
       "         9718641,  5524881,  8106730,  8542993, 11811140,  8823893,\n",
       "         5716330,  6522242,  5881893,  3439096,  2581452,  9289828,\n",
       "         4864734,  7708418,  8297017,  5176446, 10220950,  8218274,\n",
       "         6369539,  3547523,  7973419,  6946819,  9693885, 10360907,\n",
       "        10206169,  9763796, 12217403,  6365321,  5387211,  8482263,\n",
       "         5881893,  3353679, 10753922,  3534076, 10405482, 12783196,\n",
       "         8229411,  7839814, 10154994,  5179232,  3456780,  5814613,\n",
       "         6600515,  7515103,  9111849,  8381693,  6196431,  4357985,\n",
       "         8311110,  6530892,  9411943,  7971540,  4946049,  8740744,\n",
       "         4375101,  8295843,  9837578,  7732458, 10360907,  6381309,\n",
       "         4820642,  9910942,  5370302,  6061119,  8547328,  5473535,\n",
       "         7955708,  7538450,  9025557,  7765677,  4730442,  9790034,\n",
       "         4638393,  8692983,  3246984, 10155321,  2708286,  7972926,\n",
       "         8194874,  6386784,  2452185, 10670830,  4370956,  9850843,\n",
       "        11232745,  7601633, 11252512, 11922648,  8035632,  8546551,\n",
       "         8242769,  5983410,  7809755,  8542993, 11152625,  5811937,\n",
       "         4171302,  8687080,  7117178,  7839814,  9959492,  7033713,\n",
       "         2452185,  5302881,  4772953, 10337258,  9994771,  5353738,\n",
       "        10154994,  7881991,  5794713,  6029302,  6285094,  8107283,\n",
       "        10812504,  6967430,  3955026,  6780367,  7770901,  5895238,\n",
       "         5265699]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 7, 4, 1, 3, 1, 1, 4, 4, 2, 1, 5,\n",
       "        3, 2, 1, 3, 2, 1, 1, 1, 1, 2, 1, 3, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 2, 1, 2, 7, 8, 6, 3, 3, 4, 1, 2, 1, 8, 1, 4, 1, 1,\n",
       "        5, 1, 1, 1, 1, 1, 8, 1, 2, 1, 1, 5, 1, 1, 3, 2, 1, 3, 5, 1, 3, 6,\n",
       "        7, 8, 1, 6, 4, 1, 1, 1, 6, 2, 4, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 3,\n",
       "        1, 8, 3, 1, 2, 4, 6, 2, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 3, 1,\n",
       "        1, 3, 1, 1, 3, 1, 1, 1, 1, 2, 3, 1, 2, 1, 2, 1, 4, 1, 1, 5, 4, 1,\n",
       "        1, 1, 2, 8, 1, 1, 1, 2, 1, 1, 1, 1, 4, 2, 3, 1, 1, 1, 3, 1, 1, 6,\n",
       "        6, 1, 4, 1, 1, 1, 4, 1, 1, 1, 2, 1, 1, 9, 1, 1, 3, 1, 3, 2, 6, 2,\n",
       "        3, 1, 1, 1, 1, 2, 1, 1, 6, 2, 1, 2, 1, 4, 1, 3, 1, 1, 1, 1, 2, 1,\n",
       "        4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 5, 1, 1, 1, 3, 3, 1, 1, 3, 5,\n",
       "        1, 2, 1, 1, 9, 1, 1, 1, 1, 2, 1, 1, 6, 1, 2, 4, 6]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unexp=find_unexplained_FPs(csvs[2])\n",
    "unexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "491773f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 3, 2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unexp[1][np.argsort(unexp[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1c4ae4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3027, 1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(all_test['even_se_oot_norm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0dea293f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(all_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e9ce867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 7, 4, 1, 3, 1, 1, 4, 4, 2, 1, 5,\n",
       "       3, 2, 1, 3, 2, 1, 1, 1, 1, 2, 1, 3, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 2, 1, 2, 7, 8, 6, 3, 3, 4, 1, 2, 1, 8, 1, 4, 1, 1,\n",
       "       5, 1, 1, 1, 1, 1, 8, 1, 2, 1, 1, 5, 1, 1, 3, 2, 1, 3, 5, 1, 3, 6,\n",
       "       7, 8, 1, 6, 4, 1, 1, 1, 6, 2, 4, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 3,\n",
       "       1, 8, 3, 1, 2, 4, 6, 2, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 3, 1,\n",
       "       1, 3, 1, 1, 3, 1, 1, 1, 1, 2, 3, 1, 2, 1, 2, 1, 4, 1, 1, 5, 4, 1,\n",
       "       1, 1, 2, 8, 1, 1, 1, 2, 1, 1, 1, 1, 4, 2, 3, 1, 1, 1, 3, 1, 1, 6,\n",
       "       6, 1, 4, 1, 1, 1, 4, 1, 1, 1, 2, 1, 1, 9, 1, 1, 3, 1, 3, 2, 6, 2,\n",
       "       3, 1, 1, 1, 1, 2, 1, 1, 6, 2, 1, 2, 1, 4, 1, 3, 1, 1, 1, 1, 2, 1,\n",
       "       4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 5, 1, 1, 1, 3, 3, 1, 1, 3, 5,\n",
       "       1, 2, 1, 1, 9, 1, 1, 1, 1, 2, 1, 1, 6, 1, 2, 4, 6])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unexp[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
