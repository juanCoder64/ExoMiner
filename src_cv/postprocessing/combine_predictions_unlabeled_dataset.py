"""
Processes predictions generated by cross-validation experiment:
- Aggregate predictions generated by each CV iteration for each example in the dataset.
- Compute mean and std scores across all CV iterations for each example in the dataset.
"""

# 3rd party
from pathlib import Path
import pandas as pd


def aggregate_cv_fold_predictions(cv_pred_run_dir):
    """ Combine predictions from all CV iterations in the unlabeled dataset. `cv_pred_run_dir` should contain
    directories for each CV iteration named 'cv_iter_<iteration_number>'. Each CV iteration directory should contain a
    file with the predictions for the unlabeled dataset named 'ranked_predictions_predictset.csv'.

    The resulting table will contain the predictions for all CV iterations, with an additional column 'fold'.

    Args:
        cv_pred_run_dir: Path, directory containing the CV iterations directories

    Returns: ranking_tbl_cv, DataFrame with the predictions for all CV folds
    """

    # get directories of cv iterations in cv run
    cv_iters_dirs = [fp for fp in cv_pred_run_dir.iterdir() if fp.is_dir() and fp.name.startswith('cv_iter')]

    cv_iters_tbls = []
    for cv_iter_dir in cv_iters_dirs:
        ranking_tbl = pd.read_csv(cv_iter_dir / 'ranked_predictions_predictset.csv')
        ranking_tbl['fold'] = cv_iter_dir.name.split('_')[-1]
        cv_iters_tbls.append(ranking_tbl)

    ranking_tbl_cv = pd.concat(cv_iters_tbls, axis=0)

    return ranking_tbl_cv


def get_mean_std_score_statistics_across_cv_folds_predictions(cv_pred_run_dir):
    """ Get mean and std score across all folds for the prediction on the unlabeled dataset. `cv_pred_run_dir` should
    contain directories for each CV iteration named 'cv_iter_<iteration_number>'. Each CV iteration directory should
    contain a file with the predictions for the unlabeled dataset named 'ranked_predictions_predictset.csv'. This table
    should contain column 'uid' with the unique identifier for each example in the dataset and column 'score' with the
    score for that CV iteration.

    The resulting table will contain the predictions for all CV iterations with column name
    'score_fold_<iteration_number>' , with additional columns 'mean_score' and 'std_score'.

    Args:
        cv_pred_run_dir: Path, directory containing the CV iterations directories

    Returns: tbl, DataFrame with the predictions for all CV folds combined with mean and std score columns

    """

    # get directories of cv iterations in cv run
    cv_iters_dirs = [fp for fp in cv_pred_run_dir.iterdir() if fp.is_dir() and fp.name.startswith('cv_iter')]

    tbl = None
    n_folds = len(cv_iters_dirs)
    for cv_iter_dir in cv_iters_dirs:
        ranking_tbl = pd.read_csv(cv_iter_dir / 'ranked_predictions_predictset.csv')
        ranking_tbl['fold'] = cv_iter_dir.name.split('_')[-1]
        ranking_tbl[f'score_fold_{cv_iter_dir.name.split("_")[-1]}'] = ranking_tbl['score']
        if tbl is None:
            tbl = ranking_tbl
        else:
            tbl = pd.merge(tbl, ranking_tbl[['uid', f'score_fold_{cv_iter_dir.name.split("_")[-1]}']],
                           on=['uid'])

    tbl.drop(columns=['fold', 'score'], inplace=True)
    tbl['mean_score'] = tbl[[f'score_fold_{i}' for i in range(n_folds)]].mean(axis=1)
    tbl['std_score'] = tbl[[f'score_fold_{i}' for i in range(n_folds)]].std(axis=1)

    return tbl

if __name__ == '__main__':

    cv_pred_run_dir = Path('/Users/msaragoc/Projects/exoplanet_transit_classification/experiments/tess_spoc_2min/toi_2095/s14-s86/cv_predict_tess-spoc-2min_s14-s86_toi-2095_4-10-2025_1212')

    ranking_tbl_cv = aggregate_cv_fold_predictions(cv_pred_run_dir)

    ranking_tbl_cv.to_csv(cv_pred_run_dir / 'ranked_predictions_allfolds.csv', index=False)

    ranking_tbl_cv_with_stats = get_mean_std_score_statistics_across_cv_folds_predictions(cv_pred_run_dir)

    ranking_tbl_cv_with_stats.to_csv(cv_pred_run_dir / 'ranked_predictions_allfolds_avg.csv', index=False)