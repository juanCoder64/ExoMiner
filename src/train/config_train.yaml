rank: null
rnd_seed: 2  # random seed used to select the validation fold in each CV iteration
paths:
  # experiment directory; results are saved here
  experiment_root_dir: null
  # YAML file containing a list of CV iterations, where each CV iteration is a dictionary with the TFRecord filepaths
  # for each training, validation, and test set folds combination (i.e., {'train': ['/path/to/train_shard-xxxx', ...],
  # 'val': ['/path/to/val_shard-xxxx', ...], 'test': ['/path/to/test_shard-xxxx']}
  datasets_fps_yaml: null
#  # HPO run configuration directory; get configurations from an HPO run; set to null to not use any
  hpo_dir: null
  model_config_fp: /

val_from_train: false  # if true, the validation fold is chosen randomly from the training split. The training split must contain more than one fold
generate_csv_pred: true  # generates a prediction ranking for each of the specified datasets

data_fields: # scalar data from TFRecords to add to ranking table
  uid: 'string'
  target_id: 'int_scalar'
  tce_plnt_num: 'int_scalar'
  label: 'string'
  tce_period: 'float_scalar'
  tce_duration: 'float_scalar'
  tce_time0bk: 'float_scalar'
  tce_depth: 'float_scalar'
  ruwe: 'float_scalar'
  tce_prad: 'float_scalar'
  tce_max_mult_ev: 'float_scalar'

# set general architecture of the model based on implementations under models.models_keras.py
model_architecture: ExoMinerPlusPlus

features_set: # each key-value pair is feature_name: {'dim': feature_dim, 'dtype': feature_dtype}

  # unfolded flux
  unfolded_local_flux_view_fluxnorm: { 'dim': [ 20, 31 ], 'dtype': float }
  unfolded_local_flux_view_fluxnorm_var: { 'dim': [ 20, 31 ], 'dtype': float }
  tce_num_transits_norm: { 'dim': [ 1, ], 'dtype': float }
  tce_num_transits_obs_norm: { 'dim': [ 1, ], 'dtype': float }

  # flux
  global_flux_view_fluxnorm: { 'dim': [ 301, 1 ], 'dtype': float }
  global_flux_view_fluxnorm_var: { 'dim': [ 301, 1 ], 'dtype': float }
  flux_global_stat_abs_min_norm: { 'dim': [ 1, ], 'dtype': float }

  local_flux_view_fluxnorm: { 'dim': [ 31, 1 ], 'dtype': float }
  local_flux_view_fluxnorm_var: { 'dim': [ 31, 1 ], 'dtype': float }
  flux_local_stat_abs_min: { 'dim': [ 1, ], 'dtype': float }

  # odd-even flux related features
  local_flux_odd_view_fluxnorm: { 'dim': [ 31, 1 ], 'dtype': float }
  local_flux_even_view_fluxnorm: { 'dim': [ 31, 1 ], 'dtype': float }
  local_flux_odd_view_fluxnorm_var: { 'dim': [ 31, 1 ], 'dtype': float }
  local_flux_even_view_fluxnorm_var: { 'dim': [ 31, 1 ], 'dtype': float }
  flux_even_local_stat_abs_min_norm: {'dim': [1,], 'dtype': float}
  flux_odd_local_stat_abs_min_norm: {'dim': [1,], 'dtype': float}

  # centroid related features
  local_centr_view_std_noclip: { 'dim': [ 31, 1 ], 'dtype': float }
  local_centr_view_std_noclip_var: { 'dim': [ 31, 1 ], 'dtype': float }

  # secondary related features
  local_weak_secondary_view_selfnorm: { 'dim': [ 31, 1 ], 'dtype': float }
  local_weak_secondary_view_selfnorm_var: { 'dim': [ 31, 1 ], 'dtype': float }
  tce_maxmes_norm: { 'dim': [ 1, ], 'dtype': float }
  tce_albedo_stat_norm: { 'dim': [ 1, ], 'dtype': float }
  tce_ptemp_stat_norm: { 'dim': [ 1, ], 'dtype': float }
  flux_weak_secondary_local_stat_abs_min_norm: { 'dim': [ 1, ], 'dtype': float }

  # other diagnostic parameters
  tce_max_mult_ev_norm: { 'dim': [ 1, ], 'dtype': float }
  tce_max_sngle_ev_norm: { 'dim': [ 1, ], 'dtype': float }
  tce_robstat_norm: { 'dim': [ 1, ], 'dtype': float }
  tce_model_chisq_norm: { 'dim': [ 1, ], 'dtype': float }

  # bootstrap fa prob
  boot_fap_norm: { 'dim': [ 1, ], 'dtype': float }

  # ghost
  tce_cap_stat_norm: { 'dim': [ 1, ], 'dtype': float }
  tce_hap_stat_norm: { 'dim': [ 1, ], 'dtype': float }

  # stellar parameters
  tce_sdens_norm: { 'dim': [ 1, ], 'dtype': float }
  tce_steff_norm: { 'dim': [ 1, ], 'dtype': float }
  tce_smet_norm: { 'dim': [ 1, ], 'dtype': float }
  tce_slogg_norm: { 'dim': [ 1, ], 'dtype': float }
  tce_smass_norm: { 'dim': [ 1, ], 'dtype': float }
  tce_sradius_norm: { 'dim': [ 1, ], 'dtype': float }
  ruwe_norm: { 'dim': [ 1, ], 'dtype': float }
  mag_shift_norm: { 'dim': [ 1, ], 'dtype': float }

  # tce parameters
  tce_prad_norm: { 'dim': [ 1, ], 'dtype': float }
  tce_period_norm: { 'dim': [ 1, ], 'dtype': float }

  # difference image
  diff_imgs_std_trainset: { 'dim': [ 33, 33, 5 ], 'dtype': float }
  oot_imgs_std_trainset: { 'dim': [ 33, 33, 5 ], 'dtype': float }
  target_imgs: { 'dim': [ 33, 33, 5 ], 'dtype': float }

  quality: { 'dim': [ 5, 1], 'dtype': float }
  tce_dikco_msky_norm: { 'dim': [ 1, ], 'dtype': float }
  tce_dikco_msky_err_norm: { 'dim': [ 1, ], 'dtype': float }

  # momentum dump
  local_momentum_dump_view: { 'dim': [ 31, 1 ], 'dtype': float }
  local_momentum_dump_view_var: { 'dim': [ 31, 1 ], 'dtype': float }

  # flux trend
  flux_trend_global_norm: { 'dim': [ 301, 1 ], 'dtype': float }
  flux_trend_global_norm_var: { 'dim': [ 301, 1 ], 'dtype': float }
  flux_trend_global_stat_min_norm: { 'dim': [ 1, ], 'dtype': float }
  flux_trend_global_stat_max_norm: { 'dim': [ 1, ], 'dtype': float }

  # flux periodogram
  pgram_smooth_norm: { 'dim': [ 674, 1 ], 'dtype': float }
  pgram_tpm_smooth_norm: { 'dim': [ 674, 1 ], 'dtype': float }
  pgram_smooth_max_power_norm: { 'dim': [ 1, ], 'dtype': float }
  pgram_tpm_smooth_max_power_norm: { 'dim': [ 1, ], 'dtype': float }

# maps features' names to features names expected by the model
feature_map: null
#  feature_name: feature_name_model

training:
  data_augmentation: false  # perform online data augmentation
  online_preprocessing_params: # online data augmentation parameters
    'num_bins_global': 301
    'num_bins_local': 31
    'num_transit_dur': 5
  n_epochs: 300  # number of epochs used to train each model
  opt_metric: auc_pr  # metric shown in the epoch plots besides loss for the training, validation and test sets
  batch_size: 32
  filter_data: null  # deprecated; useless
  category_weights: null  # category weights used in weighted loss; set to null for non-weighted loss
  sample_weights: false  # use sample weights defined in the data set
  shuffle_buffer_size: 5000  # should be larger than size of the training set to allow perfect sampling

label_field_name: label  # name of the label field in the TFRecord that is going to be used as the label

evaluation:
  batch_size: 32
inference:
  batch_size: 32

callbacks:
  train:
    early_stopping:
      monitor: val_auc_pr  # val_auc_pr  # which metric used to monitor for early stopping
      min_delta: 0
      patience: 20
      verbose: 1
      mode: max  # maximize/minimize monitored metric in early stopping
      baseline: null
      restore_best_weights: true  # get model from epoch that had the best performance according to monitored metric
    tensorboard:
      histogram_freq: 1
      write_graph: true
      write_images: false
      update_freq: epoch
      profile_batch: 2
      embeddings_metadata: null
      embeddings_freq: 0

label_map:  # maps label to a label id
#  # Kepler
#  PC: 1
  # AFP: 0
#  NTP: 0
  # TESS
  KP: 1
  CP: 1
  FP: 0
  EB: 0
  NTP: 0
  BD: 0

datasets:
  - train
  - val
  - test

plot_model: true
write_model_summary: true
verbose_model: 2  # for fit, eval, predict functions
verbose: true  # general

metrics:
  'clf_thr': 0.5  # classification threshold
  'num_thr': 1000  # number of thresholds used to compute some metrics
