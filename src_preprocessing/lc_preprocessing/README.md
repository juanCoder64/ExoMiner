# Preprocessing data pipeline

### Goals

The code in [lc_preprocessing](../../src_preprocessing/lc_preprocessing) is used for preprocessing the light curve data generated by the SPOC pipeline to create TFRecord datasets of transit signal observations (i.e., threshold crossing events - TCEs).

### Required Inputs
Two inputs are required to run the light curve preprocessing pipeline:
- Light curve FITS files: TESS/Kepler targets light curves
- CSV table with TCEs: table containing information on the transit signals of interest

The TCE table must contain the following columns:
- uid: unique ID for the TCE in the format <kic_id>-<tce_planet_number> for Kepler (e.g., 12345678-1), and <tic_id>-<tce_planet_number>-<sector_run> for TESS (e.g., 12345678-1-S1 or 12345678-1-S1-9 for single- and multi-sector runs, respectively)
- target_id (integer): KIC/TIC ID (integer, hence without any left padding zeroes)
- tce_period (float): orbital period in days
- tce_duration (float): transit duration in hours
- tce_time0bk (float): epoch in BKJD or BTJD for Kepler and TESS, respectively
- tce_depth (float): transit depth in ppm. Set to 0 if missing
- tce_depth_err (float): uncertainty in transit depth in ppm. Set to -1 if missing
- wst_depth (float): secondary transit depth in ppm. Set to 0 if missing
- wst_depth_err (float): uncertainty in secondary transit depth in ppm. Set to -1 if missing
- tce_maxmesd (float): secondary transit offset in days from the primary transit
- ra (float): target's right ascension in degrees
- dec (float): target's declination in degrees
- sector_run (string, TESS only): sector run where the TCE was detected (e.g., '1', '1-9' for single- and multi-sector runs, respectively)
- sectors_observed (string, TESS only): sectors the target was observed for the corresponding sector run, separated by underscore (e.g., '1_3_6_9') 
- label (string): disposition assigned to the TCE. It is not required for the TCE to be assigned any specific disposition. For TCEs not dispositioned, we usually set them to 'UNK', meaning unknown.

The following columns are not needed to run the preprocessing pipeline, but they might be required as input features to the ExoMiner model (this is dependent on the architecture chosen):
- tce_num_transits_obs (float): number of transits observed
- tce_num_transits (float): expected number of transits observed
- tce_max_mult_ev (float): primary transit MES
- tce_max_sngle_ev (float): primary transit SES
- tce_robstat (float): TCE's robust statistic
- tce_model_chisq (float): TCE's model chi-square statistic
- tce_maxmes (float): secondary transit MES
- tce_prad (float): planet radius in Earth radii
- tce_albedo_stat (float): comparison statistic for the secondary albedo
- tce_ptemp_stat (float): comparison statistic for the secondary planet equilibrium temperature
- boot_fap (float): boostrap false alarm probability
- tce_cap_stat (float): ghost diagnostic core aperture statistic
- tce_hap_stat (float): ghost diagnostic halo aperture statistic
- tce_dikco_msky (float): difference image centroid offset from target's coordinates in arcsec
- tce_dikco_msky_err (float): uncertainty in difference image centroid offset from target's coordinates in arcsec
- tce_sradius (float): target's stellar radius in Solar radii
- tce_smass (float): target's stellar mass in Solar mass
- tce_smet (float): target's stellar metallicity
- tce_steff (float): target's stellar effective temperature in Kelvin
- tce_slogg (float): target's stellar surface gravity in log
- ruwe (float): target's Gaia RUWE
- mag (float): target's magnitude (Kepler Kmag or TESS TMag)

### Data Preprocessing

The main scripts involved in preprocessing the data are [generate_input_records.py](../../src_preprocessing/lc_preprocessing/generate_input_records.py)
and [preprocessing.py](../../src_preprocessing/lc_preprocessing/preprocess.py), and the configuration file [config_preprocessing.yaml](../../src_preprocessing/lc_preprocessing/config_preprocessing.yaml)\
The script [generate_input_records.py](../../src_preprocessing/lc_preprocessing/generate_input_records.py) is designed to preprocess batches of data in parallel using the
Python `multiprocessing.Pool` module, i.e., given a table of transit signals to be preprocessed, the
code splits the table into **subsets of target stars**, preprocessing each batch simultaneously. One can also use external parallel tools 
such as GNU Parallel along with script [preprocessing_job.sh](../../src_preprocessing/lc_preprocessing/preprocessing_job.sh). The configuration file [config_preprocessing.yaml](../../src_preprocessing/lc_preprocessing/config_preprocessing.yaml) contains options on 
how to run the pipeline (e.g., detrending method used, binning, gapping, outlier removal) and the filepaths to the [required inputs](#required-inputs).

#### Preprocessing Steps

The main preprocessing steps are (check [preprocessing.py](../../src_preprocessing/lc_preprocessing/preprocess.py)):

1. Get data from light curve FITS files for target stars of interest.
   1. Timestamps array: timestamps associated to the recorded cadences (a cadence is a single observation, data point).
   2. PDC-SAP flux time series (informally called 'flux'): consists of accumulated brightness for the pixels in the
      optimal aperture for the given target star.
   3. FW (flux-weighted) centroid motion time series: consists of weighted average centroid location in celestial 
   coordinates (RA and Dec) based on flux in the photometry aperture.
3. Remove stellar variability noise by fitting a trend to the timeseries, since this phenomenon occurs usually at a
   longer timescale than the transits.
4. Phase-fold the timeseries over the orbital period for the transit signal of interest.
5. Create a binned version (usually called 'view') of the phase-folded timeseries by averaging cadences in each bin.

#### Features

The features set in the TFRecords come from two sources:

1. The different time series (and periodogram) created in [generate_example_for_tce()](../../src_preprocessing/lc_preprocessing/preprocess.py).
2. Scalar features added to the TFRecords also in [generate_example_for_tce()](../../src_preprocessing/lc_preprocessing/preprocess.py) that come from the transit signal table used as input (e.g. transit depth, weak secondary MES, other statistics and diagnostics computed in the DV module of the SPOC pipeline).

### Data Format

This project uses TFRecord format to save the processed data to be ingested by the models. This format stores a sequence
of binary records. Each TFRecord file has a set of examples (data points), each one with a given set of features. Check
[TFRecord tutorial](https://www.tensorflow.org/tutorials/load_data/tfrecord) for more information.
