# source TFRecord dataset directory
src_tfrec_dir: /Users/msaragoc/Library/CloudStorage/OneDrive-NASA/Projects/exoplanet_transit_classification/data/tfrecords/kepler/tfrecordskeplerq1q17dr25-dv_g301-l31_5tr_spline_nongapped_all_features_phases_7-12-2022_1647_data/tfrecordskeplerq1q17dr25-dv_g301-l31_5tr_spline_nongapped_all_features_phases_7-12-2022_1647
# directory with tables used to split the examples into different sets (train, validation, test, predict, ...)
split_tbls_dir: /Users/msaragoc/Library/CloudStorage/OneDrive-NASA/Projects/exoplanet_transit_classification/data/dataset_splits/kepler_q1q17dr25/hongbo_split_04-10
# defines which tables are used and the prefix of the TFRecord shards; e.g., if train split table is loaded, it will
# put all examples from that table that can find in the shards in the source TFRecord dataset into shards starting with
# the prefix `train-shard`
datasets: [ 'train', 'val', 'test', 'predict' ]
omitMissing: True  # skip missing TCEs in the TFRecords that exist in the dataset tables
nProcesses: 15  # number of processes used to create the new TFRecord dataset
n_examples_per_shard: 100  # number of examples in each shard in the new TFRecord dataset; min(n_examples_per_shard, n_total_examples)
destTfrecDirName: dataset_split
