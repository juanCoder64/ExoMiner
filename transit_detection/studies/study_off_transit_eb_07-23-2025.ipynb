{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd party\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import LogNorm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import lightkurve as lk\n",
    "from collections import defaultdict\n",
    "import textwrap\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(levelname)s - %(message)s')\n",
    "\n",
    "logger = logging.getLogger(__name__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - test\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_z/srkh35f94rd_6jrkc3kv29hm0000gp/T/ipykernel_56915/1895853627.py:14: DtypeWarning: Columns (364,366,367,370,371) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tce_tbl = pd.read_csv(tce_tbl_fp)\n",
      "INFO - \n",
      "=== Split: train ===\n",
      "INFO - Total examples: 207557\n",
      "INFO - Confusion counts:\n",
      "confusion\n",
      "TP    173003\n",
      "TN     33964\n",
      "FN       575\n",
      "FP        15\n",
      "Name: count, dtype: int64\n",
      "INFO - \n",
      "CP (14148 examples)\n",
      "INFO - confusion\n",
      "TN    13239\n",
      "TP      733\n",
      "FN      165\n",
      "FP       11\n",
      "INFO -            tce_depth  tce_max_mult_ev    tce_maxmes    tce_period  tce_duration  tce_num_transits  tce_dikco_msky_original  tce_dikco_msky_err_original  tce_dicco_msky_original  tce_dicco_msky_err_original\n",
      "count   14148.000000     14148.000000  14148.000000  14148.000000  14148.000000      14148.000000             14148.000000                 14148.000000             14148.000000                 14148.000000\n",
      "mean    55759.697478        35.717691      2.720668      5.544775      1.856815        264.988196                 3.555450                     3.755043                 8.195008                     4.323769\n",
      "std    147208.866463        47.028759      0.938297      9.169517      1.459656        348.657105                 5.753047                     3.341639                13.255616                     3.691303\n",
      "min        64.628815         7.173665      1.268295      0.736283      0.239160          0.000000                 0.000000                    -1.000000                 0.000000                    -1.000000\n",
      "25%       954.962854        14.062429      2.268586      1.407937      0.941802         21.000000                 0.969200                     2.600136                 1.349421                     2.626225\n",
      "50%      1600.985570        20.833632      2.556352      3.697576      1.529753        124.000000                 2.054563                     2.871601                 2.808103                     3.024169\n",
      "75%      6690.898840        29.614279      3.026766      5.983967      2.316813        390.000000                 3.586127                     3.598617                 6.784790                     4.263646\n",
      "max    597355.538954       414.320190     18.569407    225.130133     13.280961       2406.000000                53.442621                    33.764437                55.456728                    33.181156\n",
      "INFO - CP Summary\n",
      "INFO - EB Summary\n",
      "INFO - KP Summary\n",
      "INFO - 55525572: 1 \n",
      "INFO - 267574918: 10 mixed\n",
      "INFO - 48507019: 1 \n",
      "INFO - 213047427: 1 mixed\n",
      "INFO - 152223725: 1 \n",
      "INFO - 93000166: 1 \n",
      "INFO - 55525572: 1 \n",
      "INFO - 267574918: 10 mixed\n",
      "INFO - 48507019: 1 \n",
      "INFO - 213047427: 1 mixed\n",
      "INFO - 152223725: 1 \n",
      "INFO - 93000166: 1 \n",
      "INFO - \n",
      "EB (183443 examples)\n",
      "INFO - confusion\n",
      "TP    172202\n",
      "TN     10845\n",
      "FN       392\n",
      "FP         4\n",
      "INFO -           tce_depth  tce_max_mult_ev     tce_maxmes     tce_period   tce_duration  tce_num_transits  tce_dikco_msky_original  tce_dikco_msky_err_original  tce_dicco_msky_original  tce_dicco_msky_err_original\n",
      "count  1.834430e+05    183443.000000  183443.000000  183443.000000  183443.000000     183443.000000            183443.000000                183443.000000            183443.000000                183443.000000\n",
      "mean   3.108554e+05       828.246061     198.980246       1.515368       2.449751        804.477914                 1.999488                     2.344952                 2.536870                     2.460131\n",
      "std    2.455898e+05      2917.300052     555.310443       3.622224       2.201944       1577.459495                 6.451679                     1.249447                 7.244870                     1.887875\n",
      "min    0.000000e+00         7.116082       0.000000       0.203819       0.261323          0.000000                 0.000000                    -1.000000                 0.000000                    -1.000000\n",
      "25%    1.663748e+05        59.287571      20.484282       0.325389       1.000000          0.000000                 0.304217                     2.500004                 0.167324                     2.500008\n",
      "50%    2.693631e+05       199.724854      52.518795       0.550874       1.933867         31.000000                 0.623743                     2.501459                 0.401660                     2.500158\n",
      "75%    4.153911e+05       546.138367     137.959015       1.256808       3.458524        761.000000                 1.083290                     2.508428                 1.331268                     2.502598\n",
      "max    1.384201e+07     40765.000000   20531.193359     314.616126      54.827398       6773.000000               122.873571                    52.667029               102.897692                    50.407741\n",
      "INFO - CP Summary\n",
      "INFO - EB Summary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set consists of 14148 CP examples.\n",
      "confusion\n",
      "TN    13239\n",
      "TP      733\n",
      "FN      165\n",
      "FP       11\n",
      "Name: count, dtype: int64\n",
      "train set consists of 183443 EB examples.\n",
      "confusion\n",
      "TP    172202\n",
      "TN     10845\n",
      "FN       392\n",
      "FP         4\n",
      "Name: count, dtype: int64\n",
      "train set consists of 9966 KP examples.\n",
      "confusion\n",
      "TN    9880\n",
      "TP      68\n",
      "FN      18\n",
      "Name: count, dtype: int64\n",
      "train set consists of 14148 CP examples.\n",
      "confusion\n",
      "TN    13239\n",
      "TP      733\n",
      "FN      165\n",
      "FP       11\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - KP Summary\n",
      "INFO - 55525572: 1 \n",
      "INFO - 267574918: 10 mixed\n",
      "INFO - 48507019: 1 \n",
      "INFO - 213047427: 1 mixed\n",
      "INFO - 152223725: 1 \n",
      "INFO - 93000166: 1 \n",
      "INFO - 55525572: 1 \n",
      "INFO - 267574918: 10 mixed\n",
      "INFO - 48507019: 1 \n",
      "INFO - 213047427: 1 mixed\n",
      "INFO - 152223725: 1 \n",
      "INFO - 93000166: 1 \n",
      "INFO - \n",
      "KP (9966 examples)\n",
      "INFO - confusion\n",
      "TN    9880\n",
      "TP      68\n",
      "FN      18\n",
      "INFO -            tce_depth  tce_max_mult_ev   tce_maxmes   tce_period  tce_duration  tce_num_transits  tce_dikco_msky_original  tce_dikco_msky_err_original  tce_dicco_msky_original  tce_dicco_msky_err_original\n",
      "count    9966.000000      9966.000000  9966.000000  9966.000000   9966.000000       9966.000000              9966.000000                  9966.000000              9966.000000                  9966.000000\n",
      "mean    13735.472611       120.236833     2.864413     3.907444      2.805767        139.638671                 2.619244                     3.360797                 7.083460                     3.853381\n",
      "std     17575.139348       207.186221     1.902181     3.110660      1.236926        167.744949                 6.911362                     3.007693                13.529212                     4.584271\n",
      "min       179.224846         7.122836     0.980651     1.291597      0.717181          2.000000                 0.000000                    -1.000000                 0.000000                    -1.000000\n",
      "25%      5729.324686        13.588596     2.051265     2.549566      1.959962          9.000000                 0.522718                     2.508293                 0.493663                     2.505736\n",
      "50%     11776.374556        37.341148     2.455276     3.311903      2.640477         47.000000                 0.967874                     2.558852                 1.732712                     2.551731\n",
      "75%     15390.420206       138.166183     2.895455     4.411867      3.698152        235.000000                 2.222165                     2.938447                 7.136030                     3.006848\n",
      "max    147968.580056      1480.650513    13.650750    79.583999     10.658123        919.000000               106.775709                    38.506280               108.623297                    69.348530\n",
      "INFO - CP Summary\n",
      "INFO - EB Summary\n",
      "INFO - KP Summary\n",
      "INFO - 55525572: 1 \n",
      "INFO - 267574918: 10 mixed\n",
      "INFO - 48507019: 1 \n",
      "INFO - 213047427: 1 mixed\n",
      "INFO - 152223725: 1 \n",
      "INFO - 93000166: 1 \n",
      "INFO - 55525572: 1 \n",
      "INFO - 267574918: 10 mixed\n",
      "INFO - 48507019: 1 \n",
      "INFO - 213047427: 1 mixed\n",
      "INFO - 152223725: 1 \n",
      "INFO - 93000166: 1 \n",
      "INFO - \n",
      "=== Split: val ===\n",
      "INFO - Total examples: 13868\n",
      "INFO - Confusion counts:\n",
      "confusion\n",
      "TP    9832\n",
      "TN    3966\n",
      "FN      68\n",
      "FP       2\n",
      "Name: count, dtype: int64\n",
      "INFO - \n",
      "EB (11135 examples)\n",
      "INFO - confusion\n",
      "TP    9828\n",
      "TN    1284\n",
      "FN      21\n",
      "FP       2\n",
      "INFO -           tce_depth  tce_max_mult_ev    tce_maxmes    tce_period  tce_duration  tce_num_transits  tce_dikco_msky_original  tce_dikco_msky_err_original  tce_dicco_msky_original  tce_dicco_msky_err_original\n",
      "count  1.113500e+04     11135.000000  11135.000000  11135.000000  11135.000000      11135.000000             11135.000000                 11135.000000             11135.000000                 11135.000000\n",
      "mean   3.521465e+05      1013.201250    237.692780      2.472634      2.438024        104.198114                 2.225120                     2.564669                 3.915055                     2.677413\n",
      "std    2.188233e+05      2304.384633    960.294621      4.215447      2.462064        276.206046                 7.865640                     1.052218                10.635155                     1.930298\n",
      "min    0.000000e+00         7.711442      0.000000      0.233690      0.314541          0.000000                 0.000000                    -1.000000                 0.000000                    -1.000000\n",
      "25%    1.370731e+05        66.548813     16.568274      0.364759      0.500000          0.000000                 0.244141                     2.500003                 0.182204                     2.500005\n",
      "50%    3.392725e+05       193.542175     55.456806      0.643209      1.726454          0.000000                 0.564171                     2.500777                 0.690892                     2.500047\n",
      "75%    5.243281e+05       586.995361    167.711319      2.794688      3.500000         60.000000                 1.243331                     2.511752                 1.750555                     2.501954\n",
      "max    1.716064e+06     18606.439453  10990.115234     35.890263     34.085047       1953.000000               149.687834                    16.436850               153.369469                    40.233771\n",
      "INFO - EB Summary\n",
      "INFO - CP Summary\n",
      "INFO - KP Summary\n",
      "INFO - 262412046: 2 \n",
      "INFO - 262412046: 2 \n",
      "INFO - \n",
      "CP (1571 examples)\n",
      "INFO - confusion\n",
      "TN    1571\n",
      "INFO -           tce_depth  tce_max_mult_ev   tce_maxmes   tce_period  tce_duration  tce_num_transits  tce_dikco_msky_original  tce_dikco_msky_err_original  tce_dicco_msky_original  tce_dicco_msky_err_original\n",
      "count   1571.000000      1571.000000  1571.000000  1571.000000   1571.000000       1571.000000              1571.000000                  1571.000000              1571.000000                  1571.000000\n",
      "mean    2774.982913        59.749564     3.202243     8.965088      2.617417        226.982177                 6.649595                     3.993286                 5.579121                     3.761758\n",
      "std     4852.295041       106.580150     1.440616    10.242788      1.622810        432.566294                10.632622                     2.380335                 9.593948                     1.891282\n",
      "min      246.346523         7.241431     1.305975     0.371133      0.491819          2.000000                 0.275009                     2.500138                 0.094471                     2.500371\n",
      "25%      641.263125        12.666113     2.392013     2.650232      1.539874         20.000000                 1.270501                     2.654071                 0.759162                     2.615131\n",
      "50%      927.604476        18.543949     2.941130     6.267811      2.543254         62.000000                 2.508758                     3.163281                 2.229096                     3.010378\n",
      "75%     2648.872243        52.432999     3.435729     9.531404      3.100155        180.000000                 5.750084                     3.945737                 5.222472                     3.735961\n",
      "max    49552.182344       520.548706     9.419934    84.839213      7.539741       2045.000000               106.698280                    13.438837               107.926500                    10.436115\n",
      "INFO - EB Summary\n",
      "INFO - CP Summary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set consists of 183443 EB examples.\n",
      "confusion\n",
      "TP    172202\n",
      "TN     10845\n",
      "FN       392\n",
      "FP         4\n",
      "Name: count, dtype: int64\n",
      "train set consists of 9966 KP examples.\n",
      "confusion\n",
      "TN    9880\n",
      "TP      68\n",
      "FN      18\n",
      "Name: count, dtype: int64\n",
      "train set consists of 14148 CP examples.\n",
      "confusion\n",
      "TN    13239\n",
      "TP      733\n",
      "FN      165\n",
      "FP       11\n",
      "Name: count, dtype: int64\n",
      "train set consists of 183443 EB examples.\n",
      "confusion\n",
      "TP    172202\n",
      "TN     10845\n",
      "FN       392\n",
      "FP         4\n",
      "Name: count, dtype: int64\n",
      "train set consists of 9966 KP examples.\n",
      "confusion\n",
      "TN    9880\n",
      "TP      68\n",
      "FN      18\n",
      "Name: count, dtype: int64\n",
      "val set consists of 11135 EB examples.\n",
      "confusion\n",
      "TP    9828\n",
      "TN    1284\n",
      "FN      21\n",
      "FP       2\n",
      "Name: count, dtype: int64\n",
      "val set consists of 1571 CP examples.\n",
      "confusion\n",
      "TN    1571\n",
      "Name: count, dtype: int64\n",
      "val set consists of 1162 KP examples.\n",
      "confusion\n",
      "TN    1111\n",
      "FN      47\n",
      "TP       4\n",
      "Name: count, dtype: int64\n",
      "val set consists of 11135 EB examples.\n",
      "confusion\n",
      "TP    9828\n",
      "TN    1284\n",
      "FN      21\n",
      "FP       2\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - KP Summary\n",
      "INFO - 262412046: 2 \n",
      "INFO - 262412046: 2 \n",
      "INFO - \n",
      "KP (1162 examples)\n",
      "INFO - confusion\n",
      "TN    1111\n",
      "FN      47\n",
      "TP       4\n",
      "INFO -            tce_depth  tce_max_mult_ev   tce_maxmes   tce_period  tce_duration  tce_num_transits  tce_dikco_msky_original  tce_dikco_msky_err_original  tce_dicco_msky_original  tce_dicco_msky_err_original\n",
      "count    1162.000000      1162.000000  1162.000000  1162.000000   1162.000000       1162.000000              1162.000000                  1162.000000              1162.000000                  1162.000000\n",
      "mean    23775.219253        59.802284     2.454043     3.016013      2.482307        109.193632                 1.072503                     2.702674                12.187570                     3.459172\n",
      "std     32962.576153        65.335093     0.598753     1.750502      0.798585        133.254833                 0.848834                     0.284350                17.189056                     2.886731\n",
      "min      1293.281419         7.172248     1.238556     1.018667      1.497358          2.000000                 0.084405                     2.500181                 0.024398                     2.500459\n",
      "25%      9362.974104        15.331902     2.109938     1.706330      1.804112         11.000000                 0.531737                     2.515214                 0.475976                     2.510507\n",
      "50%     12242.395417        34.111683     2.438206     2.455263      2.305535         21.000000                 0.887285                     2.577320                 1.706785                     2.609703\n",
      "75%     18489.593902        71.935417     2.606049     3.691559      2.865280        215.000000                 1.438864                     2.743526                24.352848                     2.958955\n",
      "max    195717.127396       349.334137     5.612069    20.108356      5.281434        448.000000                 5.337010                     3.678582                50.107485                    21.468841\n",
      "INFO - EB Summary\n",
      "INFO - CP Summary\n",
      "INFO - KP Summary\n",
      "INFO - 262412046: 2 \n",
      "INFO - 262412046: 2 \n",
      "INFO - \n",
      "=== Split: test ===\n",
      "INFO - Total examples: 22481\n",
      "INFO - Confusion counts:\n",
      "confusion\n",
      "TP    18877\n",
      "TN     3591\n",
      "FN       12\n",
      "FP        1\n",
      "Name: count, dtype: int64\n",
      "INFO - \n",
      "EB (20250 examples)\n",
      "INFO - confusion\n",
      "TP    18877\n",
      "TN     1360\n",
      "FN       12\n",
      "FP        1\n",
      "INFO -           tce_depth  tce_max_mult_ev    tce_maxmes    tce_period  tce_duration  tce_num_transits  tce_dikco_msky_original  tce_dikco_msky_err_original  tce_dicco_msky_original  tce_dicco_msky_err_original\n",
      "count  2.025000e+04     20250.000000  20250.000000  20250.000000  20250.000000      20250.000000             20250.000000                 20250.000000             20250.000000                 20250.000000\n",
      "mean   3.307101e+05       878.848194    202.278657      1.777755      2.475747        273.903407                 1.152765                     2.570657                 2.133914                     2.577141\n",
      "std    1.718824e+05      2086.444861    483.513237      3.335140      2.055789        609.784227                 3.772571                     0.816739                 8.791892                     0.947202\n",
      "min    0.000000e+00         7.487437      1.464211      0.232718      0.345596          0.000000                 0.000000                    -1.000000                 0.000000                    -1.000000\n",
      "25%    1.920434e+05       104.068443     40.184138      0.450071      1.000000          0.000000                 0.318326                     2.500007                 0.107244                     2.500017\n",
      "50%    3.517696e+05       258.527374     81.193962      0.587689      1.500000          0.000000                 0.688269                     2.503700                 0.283936                     2.500200\n",
      "75%    4.127166e+05       479.595551    167.823639      1.549125      3.617030         92.000000                 0.839519                     2.509350                 1.220588                     2.502986\n",
      "max    1.240604e+06     14538.462891   7729.875000     41.642191     17.039240       2177.000000                61.298317                    27.999519               101.286983                    30.067263\n",
      "INFO - EB Summary\n",
      "INFO - CP Summary\n",
      "INFO - KP Summary\n",
      "INFO - 262758522: 1 \n",
      "INFO - 262758522: 1 \n",
      "INFO - \n",
      "CP (1088 examples)\n",
      "INFO - confusion\n",
      "TN    1088\n",
      "INFO -           tce_depth  tce_max_mult_ev   tce_maxmes   tce_period  tce_duration  tce_num_transits  tce_dikco_msky_original  tce_dikco_msky_err_original  tce_dicco_msky_original  tce_dicco_msky_err_original\n",
      "count   1088.000000      1088.000000  1088.000000  1088.000000   1088.000000       1088.000000              1088.000000                  1088.000000              1088.000000                  1088.000000\n",
      "mean    4979.669320        19.359185     2.722596     9.096730      1.901331        295.270221                 3.614960                     4.163930                 3.396816                     4.034528\n",
      "std    12117.704635        16.599547     0.567345     9.551745      1.079302        533.548421                 2.270847                     2.396056                 3.475645                     2.427300\n",
      "min      178.792556         7.102342     1.667484     0.669101      0.546439          2.000000                 0.000000                    -1.000000                 0.000000                    -1.000000\n",
      "25%      524.841879        10.028076     2.342626     0.947995      0.992163         27.000000                 2.182385                     2.651530                 1.291025                     2.677697\n",
      "50%      950.302759        12.819046     2.701803     4.569904      1.602191         61.000000                 2.854538                     3.628466                 2.709428                     3.107310\n",
      "75%     3925.680987        21.855202     3.061276    15.266466      2.496694        177.000000                 4.937641                     4.297317                 5.008910                     4.233175\n",
      "max    55452.810347       124.994911     6.971223    37.697104      5.486022       1675.000000                15.722478                    12.298987                49.822322                    12.375612\n",
      "INFO - EB Summary\n",
      "INFO - CP Summary\n",
      "INFO - KP Summary\n",
      "INFO - 262758522: 1 \n",
      "INFO - 262758522: 1 \n",
      "INFO - \n",
      "KP (1143 examples)\n",
      "INFO - confusion\n",
      "TN    1143\n",
      "INFO -           tce_depth  tce_max_mult_ev   tce_maxmes   tce_period  tce_duration  tce_num_transits  tce_dikco_msky_original  tce_dikco_msky_err_original  tce_dicco_msky_original  tce_dicco_msky_err_original\n",
      "count   1143.000000      1143.000000  1143.000000  1143.000000   1143.000000       1143.000000              1143.000000                  1143.000000              1143.000000                  1143.000000\n",
      "mean   11602.812678       131.334641     3.259107     4.069795      3.066908         81.550306                 1.239632                     2.850125                 4.848096                     2.892021\n",
      "std     6014.936109       129.198105     1.580703     2.675687      1.285589        100.112191                 1.694878                     1.863528                11.206208                     1.913695\n",
      "min      486.009037         7.835351     1.412272     1.208912      1.199354          2.000000                 0.101661                     2.500103                 0.046265                     2.500033\n",
      "25%     6935.144125        23.728523     2.253276     2.684308      2.129689          9.000000                 0.376277                     2.506700                 0.329663                     2.504802\n",
      "50%    10176.887896        89.122040     2.764804     3.922743      2.768335         21.000000                 0.634055                     2.521803                 0.826707                     2.517023\n",
      "75%    16963.972195       201.397194     3.436707     5.017130      3.996000        162.000000                 1.545752                     2.634203                 2.193315                     2.607998\n",
      "max    24967.871188       449.473053     7.540968    38.583589     11.040376        362.000000                15.852555                    19.128550                56.711676                    18.663617\n",
      "INFO - EB Summary\n",
      "INFO - CP Summary\n",
      "INFO - KP Summary\n",
      "INFO - 262758522: 1 \n",
      "INFO - 262758522: 1 \n",
      "INFO - split disposition confusion  count\n",
      "train         ANY        FN    575\n",
      "train         ANY        FP     15\n",
      "train         ANY        TN  33964\n",
      "train         ANY        TP 173003\n",
      "train          CP        FN    165\n",
      "train          CP        FP     11\n",
      "train          CP        TN  13239\n",
      "train          CP        TP    733\n",
      "train          EB        FN    392\n",
      "train          EB        FP      4\n",
      "train          EB        TN  10845\n",
      "train          EB        TP 172202\n",
      "train          KP        FN     18\n",
      "train          KP        TN   9880\n",
      "train          KP        TP     68\n",
      "  val         ANY        FN     68\n",
      "  val         ANY        FP      2\n",
      "  val         ANY        TN   3966\n",
      "  val         ANY        TP   9832\n",
      "  val          CP        TN   1571\n",
      "  val          EB        FN     21\n",
      "  val          EB        FP      2\n",
      "  val          EB        TN   1284\n",
      "  val          EB        TP   9828\n",
      "  val          KP        FN     47\n",
      "  val          KP        TN   1111\n",
      "  val          KP        TP      4\n",
      " test         ANY        FN     12\n",
      " test         ANY        FP      1\n",
      " test         ANY        TN   3591\n",
      " test         ANY        TP  18877\n",
      " test          CP        TN   1088\n",
      " test          EB        FN     12\n",
      " test          EB        FP      1\n",
      " test          EB        TN   1360\n",
      " test          EB        TP  18877\n",
      " test          KP        TN   1143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val set consists of 1571 CP examples.\n",
      "confusion\n",
      "TN    1571\n",
      "Name: count, dtype: int64\n",
      "val set consists of 1162 KP examples.\n",
      "confusion\n",
      "TN    1111\n",
      "FN      47\n",
      "TP       4\n",
      "Name: count, dtype: int64\n",
      "val set consists of 11135 EB examples.\n",
      "confusion\n",
      "TP    9828\n",
      "TN    1284\n",
      "FN      21\n",
      "FP       2\n",
      "Name: count, dtype: int64\n",
      "val set consists of 1571 CP examples.\n",
      "confusion\n",
      "TN    1571\n",
      "Name: count, dtype: int64\n",
      "val set consists of 1162 KP examples.\n",
      "confusion\n",
      "TN    1111\n",
      "FN      47\n",
      "TP       4\n",
      "Name: count, dtype: int64\n",
      "test set consists of 20250 EB examples.\n",
      "confusion\n",
      "TP    18877\n",
      "TN     1360\n",
      "FN       12\n",
      "FP        1\n",
      "Name: count, dtype: int64\n",
      "test set consists of 1088 CP examples.\n",
      "confusion\n",
      "TN    1088\n",
      "Name: count, dtype: int64\n",
      "test set consists of 1143 KP examples.\n",
      "confusion\n",
      "TN    1143\n",
      "Name: count, dtype: int64\n",
      "test set consists of 20250 EB examples.\n",
      "confusion\n",
      "TP    18877\n",
      "TN     1360\n",
      "FN       12\n",
      "FP        1\n",
      "Name: count, dtype: int64\n",
      "test set consists of 1088 CP examples.\n",
      "confusion\n",
      "TN    1088\n",
      "Name: count, dtype: int64\n",
      "test set consists of 1143 KP examples.\n",
      "confusion\n",
      "TN    1143\n",
      "Name: count, dtype: int64\n",
      "test set consists of 20250 EB examples.\n",
      "confusion\n",
      "TP    18877\n",
      "TN     1360\n",
      "FN       12\n",
      "FP        1\n",
      "Name: count, dtype: int64\n",
      "test set consists of 1088 CP examples.\n",
      "confusion\n",
      "TN    1088\n",
      "Name: count, dtype: int64\n",
      "test set consists of 1143 KP examples.\n",
      "confusion\n",
      "TN    1143\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "plot_dir = Path(f\"/Users/jochoa4/Desktop/studies/study_model_preds_07-16-2025\")\n",
    "plot_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "tce_tbl_fp = Path(\n",
    "    \"/Users/jochoa4/Projects/exoplanet_transit_classification/ephemeris_tables/preprocessing_tce_tables/tess_2min_tces_dv_s1-s68_all_msectors_11-29-2023_2157_newlabels_nebs_npcs_bds_ebsntps_to_unks.csv\"\n",
    ")\n",
    "\n",
    "scores_tbls_dir = Path(\n",
    "    \"/Users/jochoa4/Desktop/pfe_transfers/predict_model_TESS_exoplanet_dataset_07-11-2025_no_ntp_no_detrend_split_norm_filtered\"\n",
    ")\n",
    "\n",
    "show_plots = False\n",
    "# -------------------- Load Data --------------------\n",
    "tce_tbl = pd.read_csv(tce_tbl_fp)\n",
    "tce_tbl = tce_tbl.rename(columns={\"uid\": \"tce_uid\", \"label\": \"disposition\"})\n",
    "\n",
    "if 'target_id' not in tce_tbl.columns:\n",
    "    logger.debug(\"target_id not in tce_tbl, adding it\")\n",
    "    tce_tbl['target_id'] = (\n",
    "        tce_tbl['tce_uid'].astype(str)\n",
    "               .str.split('-')\n",
    "               .str[0]\n",
    "               .astype(int)\n",
    "    )\n",
    "# -------------------- Helper Functions --------------------\n",
    "def _get_confusion_label(row):\n",
    "    label, pred_label = row['label'], row['pred_label']\n",
    "    if label == 0 and pred_label == 0:\n",
    "        return 'TN'\n",
    "    if label == 0 and pred_label == 1:\n",
    "        return 'FP'\n",
    "    if label == 1 and pred_label == 0:\n",
    "        return 'FN'\n",
    "    if label == 1 and pred_label == 1:\n",
    "        return 'TP'\n",
    "    return 'UNKNOWN'\n",
    "\n",
    "# -------------------- Mixed-Target Flag --------------------\n",
    "mixed_targets = {\n",
    "    tid for tid, grp in tce_tbl.groupby('target_id')\n",
    "    if grp['disposition'].isin(['EB','CP','KP']).any()\n",
    "    and grp['disposition'].isin(['NTP','NEB','NPC']).any()\n",
    "}\n",
    "\n",
    "\n",
    "tce_tbl_cols = list(tce_tbl.columns)\n",
    "log_features = ['tce_depth', 'tce_max_mult_ev', 'tce_maxmes', 'tce_period', 'tce_duration', 'tce_num_transits', 'tce_dikco_msky_original', 'tce_dikco_msky_err_original', 'tce_dicco_msky_original','tce_dicco_msky_err_original']\n",
    "linear_features = []\n",
    "feature_cols = log_features + linear_features\n",
    "feature_cols = [f for f in feature_cols if f in tce_tbl_cols]\n",
    "\n",
    "summary_rows = []\n",
    "\n",
    "all_preds_tbl = []\n",
    "for split_name in ['train', 'val', 'test']:\n",
    "    preds_tbl = preds_tbl_fp = scores_tbls_dir / f\"preds_{split_name}.csv\"\n",
    "    preds_tbl = pd.read_csv(preds_tbl_fp)\n",
    "    \n",
    "     # Extract identifiers and flags\n",
    "    preds_tbl['tce_uid'] = preds_tbl['uid'].str.split('_').str[0]\n",
    "    preds_tbl['target_id'] = preds_tbl['tce_uid'].str.split('-').str[0].astype(int)\n",
    "    preds_tbl['confusion'] = preds_tbl.apply(_get_confusion_label, axis=1)\n",
    "    preds_tbl['mixed_target_flag'] = preds_tbl['target_id'].apply(lambda t: 1 if t in mixed_targets else 0)\n",
    "\n",
    "    merge_cols = ['tce_uid'] + feature_cols\n",
    "    preds_tbl = preds_tbl.merge(\n",
    "        tce_tbl[merge_cols],\n",
    "        on=\"tce_uid\",\n",
    "        how=\"left\",\n",
    "        validate=\"many_to_one\",\n",
    "    )\n",
    "\n",
    "    preds_tbl['split'] = split_name\n",
    "    all_preds_tbl.append(preds_tbl)\n",
    "all_preds_tbl = pd.concat(all_preds_tbl)\n",
    "\n",
    "for split_name in ['train', 'val', 'test']:\n",
    "    split_plot_dir = plot_dir / split_name\n",
    "    split_plot_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Load predictions\n",
    "    preds_tbl = all_preds_tbl[all_preds_tbl['split'] == split_name].copy()\n",
    "\n",
    "    logger.info(f\"\\n=== Split: {split_name} ===\")\n",
    "    split_dir = plot_dir / split_name\n",
    "    split_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # Summaries\n",
    "    logger.info(f\"Total examples: {len(preds_tbl)}\")\n",
    "    logger.info(f\"Confusion counts:\\n{preds_tbl['confusion'].value_counts()}\" )\n",
    "\n",
    "    # Build CF df\n",
    "    for cf, df_cf in preds_tbl.groupby(\"confusion\"):\n",
    "        summary_rows.append({\n",
    "            \"split\":      split_name,\n",
    "            \"disposition\": \"ANY\",\n",
    "            \"confusion\":  cf,\n",
    "            \"count\":      len(df_cf)\n",
    "        })\n",
    "\n",
    "    # per‐disposition confusion counts\n",
    "    for disp, df_disp in preds_tbl.groupby(\"disposition\"):\n",
    "        for cf, df_cf in df_disp.groupby(\"confusion\"):\n",
    "            summary_rows.append({\n",
    "                \"split\":       split_name,\n",
    "                \"disposition\": disp,\n",
    "                \"confusion\":   cf,\n",
    "                \"count\":       len(df_cf)\n",
    "            })\n",
    "\n",
    "    for disp in preds_tbl['disposition'].unique():\n",
    "        df_disp = preds_tbl[preds_tbl['disposition'] == disp]\n",
    "        logger.info(f\"\\n{disp} ({len(df_disp)} examples)\")\n",
    "        logger.info(df_disp['confusion'].value_counts().to_string())\n",
    "        logger.info(df_disp[feature_cols].describe().to_string())\n",
    "\n",
    "        for disp in preds_tbl['disposition'].unique():\n",
    "            logger.info(f\"{disp} Summary\")\n",
    "            disp_preds_tbl = preds_tbl[preds_tbl['disposition'] == disp].copy()\n",
    "            print(f\"{split_name} set consists of {len(disp_preds_tbl)} {disp} examples.\")\n",
    "            print(disp_preds_tbl['confusion'].value_counts())\n",
    "            \n",
    "        worst_examples = {\n",
    "            cf : defaultdict(list) for cf in preds_tbl[\"confusion\"].unique()\n",
    "        }\n",
    "\n",
    "        for cf in ['FP', 'FP']:\n",
    "            worst_examples[cf] = preds_tbl[preds_tbl[\"confusion\"] == cf]\n",
    "\n",
    "            worst_targets_set = set([])\n",
    "            worst_targets_list = []\n",
    "            worst_targets_map = defaultdict(list)\n",
    "            for _, cf_data in worst_examples[cf].iterrows():\n",
    "                worst_targets_set.add(cf_data['target_id'])\n",
    "                worst_targets_list.append(cf_data['target_id'])\n",
    "                worst_targets_map[cf_data['target_id']].append(cf_data['uid'])\n",
    "\n",
    "            for t, exs in worst_targets_map.items():\n",
    "                logger.info(f\"{t}: {len(exs)} {'mixed' if int(t) in mixed_targets else ''}\")\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "logger.info(summary_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds_tbl = all_preds_tbl[all_preds_tbl['split'] == 'train']\n",
    "train_preds_tbl[(train_preds_tbl['tce_dikco_msky'] > 20.0)]['tce_uid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in tce_tbl.columns:\n",
    "    if 'FP' in list(tce_tbl[col]):\n",
    "        print(f'col: {col}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in tce_tbl.columns:\n",
    "    if 'dikco' in col:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(all_preds_tbl['pred_prob'] - all_preds_tbl['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds_tbl['tce_dikco_msky_err_original'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds_tbl['pred_err'] = all_preds_tbl.apply(lambda r: abs(r['pred_prob'] - r['label']), axis=1)\n",
    "all_preds_tbl['ratio'] = all_preds_tbl.apply(lambda r: r['tce_dikco_msky_err_original'] / (r['tce_dikco_msky_original'] + 1e-8), axis=1)\n",
    "all_preds_tbl['err_cap'] = all_preds_tbl.apply(lambda r: 0.33 * (r['tce_dikco_msky_original'] ), axis=1)\n",
    "all_preds_tbl['tic_offset_estimate'] = all_preds_tbl.apply(lambda r: r['tce_dikco_msky_err_original'] + (r['tce_dikco_msky_original']), axis=1)\n",
    "all_preds_tbl['uncer_err'] = all_preds_tbl.apply(lambda r: r['tce_dikco_msky_err_original'] / (abs(r['tce_dikco_msky_err_original'] + r['tce_dikco_msky_original'])), axis=1)\n",
    "eb_preds = all_preds_tbl[all_preds_tbl['disposition'] == 'EB']\n",
    "eb_preds['pred_err'].describe()\n",
    "cp_preds = all_preds_tbl[all_preds_tbl['disposition'] == 'CP']\n",
    "cp_preds['pred_err'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_preds = eb_preds[(eb_preds['ratio'] <  0.25) & (eb_preds['split'] == 'train')]\n",
    "ratio_preds['confusion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_eb_preds = eb_preds[(eb_preds['tce_dikco_msky_original'] < 4.2) & (eb_preds['tce_dikco_msky_err_original'] > 0)]\n",
    "print(filt_eb_preds['confusion'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_cp_preds = cp_preds[((cp_preds['tce_dikco_msky_original'] + cp_preds['tce_dikco_msky_err_original']) < 20) & (cp_preds['tce_dikco_msky_err_original'] >= 0) ]\n",
    "print(filt_cp_preds['confusion'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_preds['confusion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_eb_preds = eb_preds[((eb_preds['tce_dikco_msky_original'] + eb_preds['tce_dikco_msky_err_original']) < 5.6) & (eb_preds['tce_dikco_msky_err_original'] >= 0) ]\n",
    "print(filt_eb_preds['confusion'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_preds[((eb_preds['tce_dikco_msky_original'] < 4.2) & ( (eb_preds['tce_dikco_msky_original'] + eb_preds['tce_dikco_msky_err_original']) < 5.6) & (eb_preds['tce_dikco_msky_err_original'] >= 0)) ]['confusion'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_eb_examples = eb_preds[(( (eb_preds['tce_dikco_msky_original'] + eb_preds['tce_dikco_msky_err_original']) >= 5.6) & (eb_preds['tce_dikco_msky_err_original'] >= 0)) ]\n",
    "bad_eb_examples['confusion'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_eb_examples[bad_eb_examples['confusion'] == 'FN']['target_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_cols = ['tce_uid', 'disposition', 'tce_time0bk','tce_period', 'tce_duration', 'tce_dikco_msky_original', 'tce_dikco_msky_err_original', 'tce_dicco_msky_original', 'tce_dicco_msky_err_original']\n",
    "tce_tbl[tce_tbl['target_id'] == 420114776][offset_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tce_tbl[tce_tbl['disposition'] == 'EB']['tce_dikco_msky_err_original'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_eb_preds[(filt_eb_preds['tce_dikco_msky_original'] < 5.6)]['confusion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_eb_preds[((filt_eb_preds['tce_dikco_msky_original'] + filt_eb_preds['tce_dikco_msky_err_original']) < 4.2)]['confusion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_eb_preds[((filt_eb_preds['tce_dikco_msky_original'] + filt_eb_preds['tce_dikco_msky_err_original']) < 4.2)]['confusion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_preds['confusion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = filt_eb_preds[(filt_eb_preds['tce_dikco_msky_original'] + filt_eb_preds['tce_dikco_msky_err_original'] < (4.2 ))]\n",
    "test['confusion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_eb_preds[filt_eb_preds['confusion'] == 'FN']['target_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test['confusion'] == 'FN']['target_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test['target_id'] == 193831684]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_preds[(eb_preds['tce_dikco_msky_original'] / eb_preds['tce_dikco_msky_err_original'] > 0)]['confusion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_eb_preds = eb_preds[\n",
    "    (eb_preds['tce_dikco_msky_original'] < 4.2) &\n",
    "    (eb_preds['tce_dikco_msky_err_original'] + eb_preds['tce_dikco_msky_original'] < (5.6))\n",
    "]\n",
    "\n",
    "print(filt_eb_preds['confusion'].value_counts())\n",
    "print((filt_eb_preds['tce_dikco_msky_err_original'] > 0).sum())\n",
    "print((filt_eb_preds['tce_dikco_msky_err_original'] <= 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(eb_preds['tce_dikco_msky_original'] < 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_preds[eb_preds['tce_dikco_msky_err_original'] > eb_preds['tce_dikco_msky_original']]['confusion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_preds = all_preds_tbl[all_preds_tbl['disposition'] == 'CP']\n",
    "cp_preds['confusion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cp_preds['ratio'] < 1/3).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_cp_preds = cp_preds[cp_preds['tce_dikco_msky_original'] < 4.2]\n",
    "thr_cp_preds['confusion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_eb_preds = eb_preds[eb_preds['tce_dikco_msky_original'] < 4.2]\n",
    "thr_eb_preds['confusion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_eb_preds[thr_eb_preds['tce_dikco_msky_err_original'] <= -1.0]['confusion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(((eb_preds['label'] == 1)\n",
    "       &\n",
    "       (eb_preds['tce_dikco_msky_err_original'] >= 0)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((eb_preds['tce_dikco_msky_original'] < 0).sum())\n",
    "print((eb_preds['tce_dikco_msky_err_original'] < 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((eb_preds['tce_dikco_msky_original'] >= 0).sum())\n",
    "print((eb_preds['tce_dikco_msky_err_original'] >= 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_preds[ratio_preds['tce_dikco_msky_original'] < 4.2]['confusion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncer_preds = eb_preds[(eb_preds['ratio'] < 0.3333) & eb_preds['']]\n",
    "uncer_preds['confusion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20944 + 207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncer_preds[uncer_preds['split'] == 'train']['confusion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20759 + 196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20759 + 196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20944 + 207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20935 + 207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_preds[ratio_preds['split'] == 'train']['confusion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20361 + 207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20935 + 207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_eb_preds = eb_preds[(eb_preds['tce_dikco_msky_original'] < 4.2) & (eb_preds['tce_dikco_msky_err_original'] < eb_preds['tce_dikco_msky_err_original'])]\n",
    "print(filt_eb_preds['confusion'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_all_preds = all_preds_tbl[\n",
    "    (all_preds_tbl['tce_dikco_msky_original'] < 4.2) &\n",
    "    (all_preds_tbl['tce_dikco_msky_err_original'] < (1/3) * all_preds_tbl['tce_dikco_msky_original'])\n",
    "]\n",
    "print(filt_all_preds['confusion'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_eb_preds = eb_preds[\n",
    "    (eb_preds['tce_dikco_msky_original'] < 4.2) &\n",
    "    ((eb_preds['tce_dikco_msky_err_original'] / eb_preds['tce_dikco_msky_original']) < (1/3) )\n",
    "]\n",
    "print(filt_eb_preds['confusion'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_eb_preds = eb_preds[(eb_preds['tce_dikco_msky_original'] < 4.2) & (eb_preds['tce_dikco_msky_err_original'] > ( 0.33 * eb_preds['tce_dikco_msky_original']))]\n",
    "print(filt_eb_preds['confusion'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tce_tbl[tce_tbl['disposition'] == 'EB']['tce_dikco_msky_err_original'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_preds[(eb_preds['tce_dicco_msky_original'] <  4.2) & (eb_preds['tce_dicco_msky_err_original'] >  0.33)]['confusion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_preds['confusion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds_tbl['confusion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds_tbl[(all_preds_tbl['ratio'] < 0.25)]['confusion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_preds['tce_dicco_msky_err_original'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_preds[eb_preds['tce_dicco_msky_err_original'] == -1.0]['confusion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_preds[( ((eb_preds['tce_dikco_msky_original'] <  4.2) & (eb_preds['tce_dikco_msky_err_original'] <  (0.33 * eb_preds['tce_dikco_msky_original']))))]['confusion'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_preds[( ((eb_preds['tce_dicco_msky_original'] <  4.2) & (eb_preds['tce_dicco_msky_err_original'] <  0.33 * eb_preds['offset_estimate']) ))]['confusion'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds_tbl[( ((all_preds_tbl['tce_dicco_msky_original'] >  4.2) & (all_preds_tbl['tce_dicco_msky_err_original'] >  0.33) & (all_preds_tbl['tce_dicco_msky_err_original'] != -1.0)))]['confusion'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in [ 'ANY']:\n",
    "    print(f\"\\n{split} preds:\")\n",
    "    if split == 'ANY':\n",
    "        split_preds_tbl = all_preds_tbl\n",
    "    else:\n",
    "        split_preds_tbl = all_preds_tbl[all_preds_tbl['split'] == split]\n",
    "\n",
    "    for disp in ['EB']:\n",
    "        print(f\"\\n{disp} preds:\")\n",
    "        disp_preds = split_preds_tbl[split_preds_tbl['disposition'] == disp]\n",
    "        print(disp_preds[(disp_preds['tce_dicco_msky_original'] <  4.2) & ((disp_preds['tce_dicco_msky_err_original'] <  0.33)) ]['confusion'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_preds[( (eb_preds['tce_dicco_msky_original'] >  4.2) & ((eb_preds['tce_dicco_msky_err_original'] / eb_preds['tce_dicco_msky_original']) < 0.33))]['confusion'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_preds[eb_preds['tce_dicco_msky_err_original'] <  0.25]['confusion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_preds[eb_preds['ratio'] < 0.2]['confusion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = eb_preds.apply(lambda r: r['tce_dikco_msky_err_original'] / abs(r['tce_dikco_msky_original'] + 1e-8), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est[est > 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_preds[eb_preds['tce_dikco_msky_original'] > 0]['pred_err'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tce_subset_df['tce_dikco_msky']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tce_subset_df = tce_tbl[tce_tbl['tce_uid'] == '420114776-1-S24']\n",
    "for col in tce_subset_df.columns:\n",
    "    if pd.api.types.is_numeric_dtype(tce_subset_df[col]):\n",
    "        if (tce_subset_df[col] > 20).any() and (tce_subset_df[col] < 21).any():\n",
    "            print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tce_tbl['TFOPWG Disposition'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split, df in summary_df[summary_df['disposition'] != 'ANY'].groupby(\"split\"):\n",
    "    pivot_split = (\n",
    "        df.pivot(index=\"disposition\", columns=\"confusion\", values=\"count\")\n",
    "          .fillna(0)\n",
    "          .loc[:, [\"FN\",\"FP\"]]\n",
    "    )\n",
    "    fig, ax = plt.subplots(figsize=(5,4))\n",
    "    pivot_split.plot(kind=\"bar\", stacked=False, ax=ax)\n",
    "    ax.set_title(f\"{split.capitalize()} Set\")\n",
    "    ax.set_xlabel(\"Disposition\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.legend(title=\"Outcome\", bbox_to_anchor=(1.02,1), loc=\"upper left\")\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = all_preds_tbl[all_preds_tbl['split'] == 'train']\n",
    "train_preds[train_preds['disposition'] == 'KP']['label'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split_name, preds_tbl in all_preds_tbl.groupby('split'):\n",
    "    logger.info(f\"{split_name} set consists of {len(preds_tbl)} examples.\")\n",
    "    logger.info(preds_tbl['label'].value_counts())\n",
    "    for disp in preds_tbl['disposition'].unique():\n",
    "        logger.info(f\"{disp} Summary\")\n",
    "        disp_preds_tbl = preds_tbl[preds_tbl['disposition'] == disp].copy()\n",
    "        logger.info(f\"Train set consists of {len(disp_preds_tbl)} {disp} examples.\")\n",
    "        logger.info(disp_preds_tbl['label'].value_counts())\n",
    "    false_examples = {\n",
    "        cf : defaultdict(list) for cf in ['FN', 'FP']\n",
    "    }\n",
    "    false_examples[\"FP\"] = preds_tbl[preds_tbl[\"confusion\"] == \"FP\"]\n",
    "    false_examples[\"FN\"] = preds_tbl[preds_tbl[\"confusion\"] == \"FN\"]\n",
    "\n",
    "    logger.info(f\"{split_name} set has {len(false_examples['FP']) + len(false_examples['FN'])} incorrect predictions.\")\n",
    "    \n",
    "    for cf, cf_df in false_examples.items():\n",
    "        logger.info(f\"{split_name} has {len(cf_df)} {cf} examples coming from {len(cf_df['tce_uid'].unique())} unique TCEs and {len(cf_df['target_id'].unique())} unique targets.\")\n",
    "        logger.info(f\"Target list: {cf_df['target_id'].unique()}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split_name, preds_tbl in all_preds_tbl.groupby('split'):\n",
    "    logger.info(f\"{split_name} set consists of {len(preds_tbl)} examples.\")\n",
    "    logger.info(preds_tbl['confusion'].value_counts())\n",
    "    for disp in preds_tbl['disposition'].unique():\n",
    "        logger.info(f\"{disp} Summary\")\n",
    "        disp_preds_tbl = preds_tbl[preds_tbl['disposition'] == disp].copy()\n",
    "        logger.info(f\"Train set consists of {len(disp_preds_tbl)} {disp} examples.\")\n",
    "        logger.info(disp_preds_tbl['confusion'].value_counts())\n",
    "    false_examples = {\n",
    "        cf : defaultdict(list) for cf in ['FN', 'FP']\n",
    "    }\n",
    "    false_examples[\"FP\"] = preds_tbl[preds_tbl[\"confusion\"] == \"FP\"]\n",
    "    false_examples[\"FN\"] = preds_tbl[preds_tbl[\"confusion\"] == \"FN\"]\n",
    "\n",
    "    logger.info(f\"{split_name} set has {len(false_examples['FP']) + len(false_examples['FN'])} incorrect predictions.\")\n",
    "    \n",
    "    for cf, cf_df in false_examples.items():\n",
    "        logger.info(f\"{split_name} has {len(cf_df)} {cf} examples coming from {len(cf_df['tce_uid'].unique())} unique TCEs and {len(cf_df['target_id'].unique())} unique targets.\")\n",
    "        logger.info(f\"Target list: {cf_df['target_id'].unique()}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_map = {}\n",
    "for split_name in ['val', 'test', 'train']:\n",
    "    logger.info(f\"Analyzing split: {split_name}\")\n",
    "    df_split = all_preds_tbl[all_preds_tbl['split'] == split_name]\n",
    "\n",
    "    # only need FN & FP\n",
    "    false_examples = {\n",
    "        'FP': df_split[df_split['confusion'] == 'FP'],\n",
    "        'FN': df_split[df_split['confusion'] == 'FN']\n",
    "    }\n",
    "\n",
    "    example_map[split_name] = {}\n",
    "    for cf, df_cf in false_examples.items():\n",
    "        example_map[split_name][cf] = {}\n",
    "        for t in df_cf['target_id'].unique():\n",
    "            df_t = df_cf[df_cf['target_id'] == t]\n",
    "            example_map[split_name][cf][t] = {}\n",
    "            for tce_uid in df_t['tce_uid'].unique():\n",
    "                # grab all rows for this target+TCE\n",
    "                uids = df_t[df_t['tce_uid'] == tce_uid]['uid'].tolist()\n",
    "                example_map[split_name][cf][t][tce_uid] = uids\n",
    "\n",
    "        logger.info(f\"{split_name} | {cf} Summary:\")\n",
    "        logger.info(df_cf[['pred_label','pred_prob']].describe().to_string())\n",
    "        logger.info(f\"{split_name} | {cf} Unique TCEs: {df_cf['tce_uid'].unique()}\")\n",
    "        logger.info(f\"{split_name} | {cf} Unique Targets: {df_cf['target_id'].unique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for info in example_map['val'].items():\n",
    "    print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl = '   '\n",
    "for split in ['train', 'test', 'val']:\n",
    "    print(f\"{nl * 0} {split}\")\n",
    "    for cf in ['FP', 'FN']:\n",
    "        print(f\"{nl * 1} {cf}\")\n",
    "        for target in example_map[split][cf]:\n",
    "            print(f\"{nl * 2} {target}\")\n",
    "            for tce_uid, examples in example_map[split][cf][target].items():\n",
    "                print(f\"{nl * 3} {tce_uid} : {[str(round(float(e.split('_t_')[-1]), 2)) for e in examples]}\")\n",
    "            \n",
    "\n",
    "print(example_map['train']['FP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "splits = ['val', 'test', 'train']\n",
    "for split in splits:\n",
    "    df_split = all_preds_tbl[all_preds_tbl['split'] == split]\n",
    "    for cf in ['FP','FN']:\n",
    "        df_cf = df_split[df_split['confusion'] == cf]\n",
    "\n",
    "        # 1) Compute per-(target, tce_uid) mean confidence\n",
    "        tce_means = (\n",
    "            df_cf\n",
    "            .groupby(['target_id','tce_uid'])['pred_prob']\n",
    "            .mean()\n",
    "            .rename('tce_avg')\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        # 2) Compute per-target mean of those tce_uids\n",
    "        target_means = (\n",
    "            tce_means\n",
    "            .groupby('target_id')['tce_avg']\n",
    "            .mean()\n",
    "            .rename('target_avg')\n",
    "            .sort_values(ascending=False)\n",
    "        )\n",
    "\n",
    "        print(f\"\\n=== {split} | {cf} ===\")\n",
    "        for target_id, target_avg in target_means.items():\n",
    "            print(f\"Target {target_id:>10}  ➜  avg prob = {target_avg:.3f}\")\n",
    "\n",
    "            # pull out all the tce's for this target and sort them\n",
    "            tces = (\n",
    "                tce_means[tce_means['target_id'] == target_id]\n",
    "                .set_index('tce_uid')['tce_avg']\n",
    "                .sort_values(ascending=False)\n",
    "            )\n",
    "\n",
    "            for tce_uid, tce_avg in tces.items():\n",
    "                # list all the underlying uids for context\n",
    "                uids = (\n",
    "                    df_cf\n",
    "                    .loc[\n",
    "                        (df_cf['target_id']==target_id)&\n",
    "                        (df_cf['tce_uid']==tce_uid),\n",
    "                        'uid'\n",
    "                    ]\n",
    "                    .tolist()\n",
    "                )\n",
    "                print(f\"    TCE {tce_uid:>8}  ➜  avg prob = {tce_avg:.3f} from {len(uids)} examples \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _summarize_tce_examples(tce_uid: str):\n",
    "    interest_cols = ['tce_uid', 'disposition', 'tce_time0bk','tce_period', 'tce_duration', 'tce_maxmes', 'tce_maxmesd']\n",
    "    t_tce_tbl_filt = tce_tbl[(tce_tbl['target_id'] == int(tce_uid.split('-')[0]))].copy()\n",
    "    logger.info(t_tce_tbl_filt[interest_cols])\n",
    "    \n",
    "    tce_tbl_filt = tce_tbl[(tce_tbl['target_id'] == int(tce_uid.split('-')[0])) & (tce_tbl['sector_run'] == tce_uid.split('S')[-1].split('_')[0])]\n",
    "    logger.info(tce_tbl_filt[interest_cols])\n",
    "    tce_preds_tbl = all_preds_tbl[all_preds_tbl[\"tce_uid\"] == tce_uid].copy()\n",
    "    logger.info(f\"Dataset has {len(tce_preds_tbl)} examples corresponding to {tce_preds_tbl['disposition'].unique()[0]}, {tce_uid} \")\n",
    "    logger.info(f\"Confusion counts: \\n {textwrap.indent(tce_preds_tbl['confusion'].value_counts().to_string(), ' ' * 4)}\")\n",
    "    logger.info(f\"Transit Window Counts: \\n {textwrap.indent(tce_preds_tbl['tw_flag'].value_counts().to_string(), ' ' * 4)}\")\n",
    "    logger.info(f\"Stats by Confusion Label: \")\n",
    "    for cf in tce_preds_tbl['confusion'].unique():\n",
    "        logger.info(f\"{' ' * 4}{cf} Stats:\")\n",
    "        desc = tce_preds_tbl[tce_preds_tbl['confusion'] == cf]['pred_prob'].describe()[1:]\n",
    "        logger.info(f\"{textwrap.indent(desc.to_string(), ' ' * 8)}\")\n",
    "    \n",
    "_summarize_tce_examples(\"30450412-1-S12\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at average correctness by target and TCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds_tbl.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = ['val','test','train']\n",
    "for split in splits:\n",
    "    # 1) select split\n",
    "    df = all_preds_tbl[all_preds_tbl['split']==split].copy()\n",
    "\n",
    "    # 2) define correctness: if true_label==1, use pred_prob; else use 1–pred_prob\n",
    "    df['correctness'] = (\n",
    "        df['pred_prob'] * df['label'] +\n",
    "        (1 - df['pred_prob']) * (1 - df['label'])\n",
    "    )\n",
    "\n",
    "    # 3) average up to the TCE level\n",
    "    tce_corr = (\n",
    "        df\n",
    "        .groupby(['target_id','tce_uid'])['correctness']\n",
    "        .mean()\n",
    "        .rename('tce_corr')\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # 4) average those TCE‐means to the target level\n",
    "    target_corr = (\n",
    "        tce_corr\n",
    "        .groupby('target_id')['tce_corr']\n",
    "        .mean()\n",
    "        .rename('target_corr')\n",
    "        .reset_index()\n",
    "        .sort_values('target_corr', ascending=False)\n",
    "    )\n",
    "\n",
    "    # 5) display\n",
    "    print(f\"\\n=== Split: {split} — target‐level correctness ===\")\n",
    "    for _, row in target_corr.iterrows():\n",
    "        print(f\"Target {int(row['target_id'])}  ➜  avg correctness = {row['target_corr']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = ['val', 'test', 'train']\n",
    "for split in splits:\n",
    "    df = all_preds_tbl[all_preds_tbl['split'] == split].copy()\n",
    "\n",
    "    for cf in ['FP', 'FN']:\n",
    "        df_wrong = df[df['confusion'] == cf]\n",
    "\n",
    "        # Count wrong examples per TCE (target_id + tce_uid)\n",
    "        tce_counts = (\n",
    "            df_wrong\n",
    "            .groupby(['target_id', 'tce_uid'])\n",
    "            .size()\n",
    "            .rename('num_wrong_examples')\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        # Count total wrong examples per target\n",
    "        target_counts = (\n",
    "            tce_counts\n",
    "            .groupby('target_id')['num_wrong_examples']\n",
    "            .sum()\n",
    "            .rename('total_wrong_examples')\n",
    "            .reset_index()\n",
    "            .sort_values('total_wrong_examples', ascending=False)\n",
    "        )\n",
    "\n",
    "        # === DISPLAY per-target ===\n",
    "        print(f\"\\n=== Split: {split} | {cf} — total wrong examples per target ===\")\n",
    "        for row in target_counts.itertuples(index=False):\n",
    "            print(f\"Target {int(row.target_id)}  ➜  total wrong = {row.total_wrong_examples}\")\n",
    "\n",
    "        # === DISPLAY per-TCE within target ===\n",
    "        print(f\"\\n=== Split: {split} | {cf} — wrong examples per TCE ===\")\n",
    "        tce_counts_sorted = tce_counts.sort_values(['target_id', 'num_wrong_examples'], ascending=[True, False])\n",
    "        for row in tce_counts_sorted.itertuples(index=False):\n",
    "            print(f\"Target {int(row.target_id)} | TCE {row.tce_uid}  ➜  wrong examples = {row.num_wrong_examples}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_cols = ['tce_uid', 'disposition', 'tce_time0bk','tce_period', 'tce_duration', 'tce_maxmes', 'tce_maxmesd']\n",
    "tce_tbl[tce_tbl['target_id'] == 356473034][interest_cols]\n",
    "# tce_tbl[(tce_tbl['target_id'] == 410418820) & (tce_tbl['sector_run'] == '1-36')][interest_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split_name, preds_tbl in all_preds_tbl.groupby('split'):\n",
    "    logger.info(f\"{split_name} set consists of {len(preds_tbl)} examples.\")\n",
    "    logger.info(preds_tbl['confusion'].value_counts())\n",
    "    for disp in preds_tbl['disposition'].unique():\n",
    "        logger.info(f\"{disp} Summary\")\n",
    "        disp_preds_tbl = preds_tbl[preds_tbl['disposition'] == disp].copy()\n",
    "        logger.info(f\"Train set consists of {len(disp_preds_tbl)} {disp} examples.\")\n",
    "        logger.info(disp_preds_tbl['confusion'].value_counts())\n",
    "    false_examples = worst_examples = {\n",
    "        cf : defaultdict(list) for cf in ['FN', 'FP']\n",
    "    }\n",
    "    false_examples[\"FP\"] = preds_tbl[preds_tbl[\"confusion\"] == \"FP\"]\n",
    "    false_examples[\"FN\"] = preds_tbl[preds_tbl[\"confusion\"] == \"FN\"]\n",
    "\n",
    "    logger.info(f\"{split_name} set has {len(false_examples['FP']) + len(false_examples['FN'])} incorrect predictions.\")\n",
    "    \n",
    "    for cf, cf_df in false_examples.items():\n",
    "        logger.info(f\"{split_name} has {len(cf_df)} {cf} examples coming from {len(cf_df['tce_uid'].unique())} unique TCEs and {len(cf_df['target_id'].unique())} unique targets.\")\n",
    "        logger.info(f\"Target list: {cf_df['target_id'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Train set consists of {len(preds_tbl)} examples.\")\n",
    "logger.info(preds_tbl['confusion'].value_counts())\n",
    "\n",
    "for disp in preds_tbl['disposition'].unique():\n",
    "    logger.info(f\"{disp} Summary\")\n",
    "    disp_preds_tbl = preds_tbl[preds_tbl['disposition'] == disp].copy()\n",
    "    logger.info(f\"Train set consists of {len(disp_preds_tbl)} {disp} examples.\")\n",
    "    logger.info(disp_preds_tbl['confusion'].value_counts())\n",
    "worst_examples = {\n",
    "    cf : defaultdict(list) for cf in preds_tbl[\"confusion\"].unique()\n",
    "}\n",
    "\n",
    "num_examples = 200\n",
    "# Get most confident FP/TN predictions\n",
    "fp_df = preds_tbl[preds_tbl[\"confusion\"] == \"FP\"]\n",
    "worst_examples[\"FP\"] = fp_df.nlargest(num_examples, columns=[\"pred_prob\"])\n",
    "\n",
    "tn_df = preds_tbl[preds_tbl[\"confusion\"] == \"TN\"]\n",
    "worst_examples[\"TN\"] = tn_df.nlargest(num_examples, columns=[\"pred_prob\"])\n",
    "\n",
    "# Get least confident TP/FN predictions\n",
    "tp_df = preds_tbl[preds_tbl[\"confusion\"] == \"TP\"]\n",
    "worst_examples[\"TP\"] = tp_df.nsmallest(num_examples, columns=[\"pred_prob\"])\n",
    "\n",
    "fn_df = preds_tbl[preds_tbl[\"confusion\"] == \"FN\"]\n",
    "worst_examples[\"FN\"] = fn_df.nsmallest(num_examples, columns=[\"pred_prob\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "len(fn_df[\"target_id\"].unique())\n",
    "logger.info(f\"{len(fn_df[fn_df['tw_flag'] < 0])}\")\n",
    "fn_df.describe()\n",
    "fn_df[\"mixed\"] = fn_df.apply(lambda r: 1 if int(r['target_id']) in mixed_targets else 0, axis=1)\n",
    "\n",
    "logger.info(f\"MIXED FNs: {fn_df['mixed'].sum()}/{len(fn_df)}\")\n",
    "\n",
    "fn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ex_at_mixed_target = {}\n",
    "for cf, exs_df in worst_examples.items():\n",
    "    exs_df[\"mixed_target_flag\"] = exs_df.apply(lambda r: 1 if int(r['target_id']) in mixed_targets else 0, axis=1)\n",
    "    # logger.info(f\"{cf}: {exs_df['mixed_target_flag'].sum()} / {} are mixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(worst_examples[\"FN\"][\"target_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# worst_examples[\"FP\"][\"target_id\"].unique()\n",
    "worst_examples[\"FN\"][20:40]#[\"target_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "worst_targets_set = set([])\n",
    "worst_targets_list = []\n",
    "worst_targets_map = defaultdict(list)\n",
    "for _, fn in worst_examples[\"FN\"].iterrows():\n",
    "    logger.info(f\"{fn['target']}, {fn['uid']}, {fn['pred_prob']}\")\n",
    "    worst_targets_set.add(fn['target'])\n",
    "    worst_targets_list.append(fn['target'])\n",
    "    worst_targets_map[fn['target']].append(fn['uid'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(worst_targets_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t, exs in worst_targets_map.items():\n",
    "    logger.info(f\"{t}: {len(exs)} {'mixed' if int(t) in mixed_targets else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_targets_map[\"358232450\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_cols = ['tce_uid', 'disposition', 'tce_time0bk','tce_period', 'tce_duration', 'tce_maxmes', 'tce_maxmesd']\n",
    "tce_tbl[tce_tbl['target_id'] == 358232450][interest_cols]\n",
    "# tce_tbl[(tce_tbl['target_id'] == 410418820) & (tce_tbl['sector_run'] == '1-36')][interest_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _summarize_tce_examples(tce_uid: str):\n",
    "    interest_cols = ['tce_uid', 'disposition', 'tce_time0bk','tce_period', 'tce_duration', 'tce_maxmes', 'tce_maxmesd']\n",
    "    t_tce_tbl_filt = tce_tbl[(tce_tbl['target_id'] == int(tce_uid.split('-')[0]))].copy()\n",
    "    logger.info(t_tce_tbl_filt[interest_cols])\n",
    "    \n",
    "    tce_tbl_filt = tce_tbl[(tce_tbl['target_id'] == int(tce_uid.split('-')[0])) & (tce_tbl['sector_run'] == tce_uid.split('S')[-1].split('_')[0])]\n",
    "    logger.info(tce_tbl_filt[interest_cols])\n",
    "    tce_preds_tbl = preds_tbl[preds_tbl[\"tce_uid\"] == tce_uid].copy()\n",
    "    logger.info(f\"Dataset has {len(tce_preds_tbl)} examples corresponding to {tce_preds_tbl['disposition'].unique()[0]}, {tce_uid} \")\n",
    "    logger.info(f\"Confusion counts: \\n {textwrap.indent(tce_preds_tbl['confusion'].value_counts().to_string(), ' ' * 4)}\")\n",
    "    logger.info(f\"Transit Window Counts: \\n {textwrap.indent(tce_preds_tbl['tw_flag'].value_counts().to_string(), ' ' * 4)}\")\n",
    "    logger.info(f\"Stats by Confusion Label: \")\n",
    "    for cf in tce_preds_tbl['confusion'].unique():\n",
    "        logger.info(f\"{' ' * 4}{cf} Stats:\")\n",
    "        desc = tce_preds_tbl[tce_preds_tbl['confusion'] == cf]['pred_prob'].describe()[1:]\n",
    "        logger.info(f\"{textwrap.indent(desc.to_string(), ' ' * 8)}\")\n",
    "    \n",
    "_summarize_tce_examples(\"189476500-1-S1-36\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _summarize_target_examples(target_id: str):    \n",
    "    target_preds_tbl = preds_tbl[preds_tbl[\"target_id\"] == int(target_id)].copy()\n",
    "    logger.info(f\"Dataset has {len(target_preds_tbl)} examples corresponding to {target_id}\\n\")\n",
    "    for tce_uid in target_preds_tbl[\"tce_uid\"].unique():\n",
    "        tce_preds_tbl = target_preds_tbl[target_preds_tbl[\"tce_uid\"] == tce_uid].copy()\n",
    "        logger.info(f\"Dataset has {len(tce_preds_tbl)} examples corresponding to {tce_preds_tbl['disposition'].unique()[0]}, {tce_uid} \")\n",
    "        logger.info(f\"Confusion counts: \\n {textwrap.indent(tce_preds_tbl['confusion'].value_counts().to_string(), ' ' * 4)}\")\n",
    "        logger.info(f\"Transit Window Counts: \\n {textwrap.indent(tce_preds_tbl['tw_flag'].value_counts().to_string(), ' ' * 4)}\")\n",
    "        logger.info(f\"Stats by Confusion Label: \")\n",
    "        for cf in tce_preds_tbl['confusion'].unique():\n",
    "            logger.info(f\"{' ' * 4}{cf} Stats:\")\n",
    "            desc = tce_preds_tbl[tce_preds_tbl['confusion'] == cf]['pred_prob'].describe()[1:]\n",
    "            logger.info(f\"{textwrap.indent(desc.to_string(), ' ' * 8)}\")\n",
    "        \n",
    "\n",
    "_summarize_target_examples('4164713')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = preds_tbl[preds_tbl[\"target_id\"] == 189476500]\n",
    "temp_df[temp_df['confusion'] == 'FP'][['uid', 'confusion', 'pred_prob']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _logger.info_tce_preds(tce_uid):\n",
    "    # interest_cols = ['tce_uid', 'disposition', 'tce_time0bk','tce_period', 'tce_duration', 'tce_maxmes', 'tce_maxmesd']\n",
    "    preds_tbl_filt = preds_tbl[preds_tbl['tce_uid'] == tce_uid].copy()\n",
    "    for _, ex in preds_tbl_filt.iterrows():\n",
    "        if float(ex['time']) > 2899 and float(ex['time']) < 2900:\n",
    "            logger.info(ex[['uid', 'confusion', 'disposition', 'label', 'pred_prob']])\n",
    "\n",
    "_logger.info_tce_preds('388431711-4-S14-60')\n",
    "_logger.info_tce_preds('388431711-1-S14-60')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing Examples\n",
    "\n",
    "tce_tbl[(tce_tbl['tce_uid'] == '148158540-3-S11') | (tce_tbl['tce_uid'] == '148158540-1-S11')][['tce_uid', 'disposition', 'tce_time0bk','tce_period', 'tce_duration', 'tce_maxmes', 'tce_maxmesd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tce_tbl[(tce_tbl['tce_uid'] == '26489741-1-S40')][['tce_uid', 'disposition', 'tce_time0bk','tce_period', 'tce_duration', 'tce_maxmes', 'tce_maxmesd', 'tec_fluxtriage_comment']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_maxmes_by_target(df):\n",
    "    return df.groupby('target_id')['maxmes'].mean().dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb = tce_tbl[tce_tbl['disposition'] == 'EB']\n",
    "cp = tce_tbl[tce_tbl['disposition'] == 'CP']\n",
    "kp = tce_tbl[tce_tbl['disposition'] == 'KP']\n",
    "combined = tce_tbl[tce_tbl['disposition'].isin(['EB', 'CP', 'KP'])]\n",
    "\n",
    "for name, df in [('EB', eb), ('CP', cp), ('KP', kp), ('ALL', combined)]:\n",
    "    plt.figure()\n",
    "    data = df['tce_maxmes'].dropna()\n",
    "    plt.hist(data, bins=100)\n",
    "    plt.title(f'Distribution of maxmes for {name} TCEs')\n",
    "    plt.xlabel('maxmes')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.tight_layout()\n",
    "    plt.xlim((0,data.quantile(0.99) ))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tce_uid = \"188768068-1-S14-26\"  # \"198408416-1-S14-60\"  # '425064757-1-S1-65'   # '198408416-1-S14-60'\n",
    "\n",
    "examples_tce = preds_tbl.loc[preds_tbl[\"tce_uid\"] == tce_uid]\n",
    "disp_tce = examples_tce[\"disposition\"].values[0]\n",
    "mes_tce = examples_tce[\"tce_max_mult_ev\"].values[0]\n",
    "\n",
    "transit_window_examples = examples_tce.loc[examples_tce[\"label\"] == 1]\n",
    "not_transit_window_examples = examples_tce.loc[examples_tce[\"label\"] == 0]\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.scatter(\n",
    "    transit_window_examples[\"time\"],\n",
    "    transit_window_examples[\"pred_prob\"],\n",
    "    s=8,\n",
    "    alpha=0.3,\n",
    "    edgecolors=\"k\",\n",
    "    label=\"Transit Window Examples\",\n",
    ")\n",
    "ax.scatter(\n",
    "    not_transit_window_examples[\"time\"],\n",
    "    not_transit_window_examples[\"pred_prob\"],\n",
    "    s=8,\n",
    "    alpha=0.3,\n",
    "    edgecolors=\"k\",\n",
    "    label=\"Not-Transit Window Examples\",\n",
    ")\n",
    "ax.set_ylabel(\"Model Score\")\n",
    "ax.set_xlabel(\"Timestamp [BTJD]\")\n",
    "ax.set_ylim(bins_scores[[0, -1]])\n",
    "ax.legend()\n",
    "ax.set_title(\n",
    "    f\"TCE {tce_uid}\\nDisposition {disp_tce}\\nNumber of examples\"\n",
    "    f\" {len(examples_tce)} | TCE Max MES {mes_tce:.3f}\"\n",
    ")\n",
    "f.tight_layout()\n",
    "f.savefig(\n",
    "    plot_dir / f\"scatter_transit_nottransit_examples_scores_{tce_uid}_{disp_tce}.png\"\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "bins_scores = np.linspace(0, 1, 11)\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "ax.hist(\n",
    "    transit_window_examples[\"pred_prob\"],\n",
    "    bins_scores,\n",
    "    histtype=\"step\",\n",
    "    label=\"Transit Window Examples\",\n",
    ")\n",
    "ax.hist(\n",
    "    not_transit_window_examples[\"pred_prob\"],\n",
    "    bins_scores,\n",
    "    histtype=\"step\",\n",
    "    label=\"Not-Transit Window Examples\",\n",
    ")\n",
    "ax.set_xlabel(\"Model Score\")\n",
    "ax.set_ylabel(\"Example Count\")\n",
    "ax.set_xlim(bins_scores[[0, -1]])\n",
    "ax.legend()\n",
    "ax.set_title(\n",
    "    f\"TCE {tce_uid}\\nDisposition {disp_tce}\\nNumber of examples\"\n",
    "    f\" {len(examples_tce)} | TCE Max MES {mes_tce:.3f}\"\n",
    ")\n",
    "f.tight_layout()\n",
    "f.savefig(\n",
    "    plot_dir / f\"hist_transit_nottransit_examples_scores_{tce_uid}_{disp_tce}.png\"\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tce_uid =  \"188768068-1-S14-26\" #\"352954787-1-S14-26\"  # \"198408416-1-S14-60\"  # '425064757-1-S1-65'   # '198408416-1-S14-60'\n",
    "lc_dir = Path(\"/Users/jochoa4/Downloads/\")\n",
    "sector_arr = list(range(14, 27))\n",
    "\n",
    "\n",
    "tce = tce_tbl.loc[tce_tbl[\"tce_uid\"] == tce_uid]\n",
    "\n",
    "# find light curve data for target\n",
    "search_lc_res = lk.search_lightcurve(\n",
    "    target=f\"tic{tce['target_id'].values[0]}\",\n",
    "    mission=\"TESS\",\n",
    "    author=(\"TESS-SPOC\", \"SPOC\"),\n",
    "    exptime=120,\n",
    "    cadence=\"long\",\n",
    "    sector=sector_arr,\n",
    ")\n",
    "\n",
    "lcf = search_lc_res.download_all(\n",
    "    download_dir=str(lc_dir), quality_bitmask=\"default\", flux_column=\"pdcsap_flux\"\n",
    ")\n",
    "\n",
    "\n",
    "def lcf_masked_quantity_corrector(lcf: lk.LightCurve) -> lk.LightCurve:\n",
    "    lcf = lk.LightCurve({\"time\": lcf.time.value, \"flux\": np.array(lcf.flux.value)})\n",
    "    return lcf.normalize()\n",
    "\n",
    "\n",
    "lcf = lcf.stitch(corrector_func=lcf_masked_quantity_corrector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t0, win_label = 1966.07, 0  # 2425.47, 0  # 2424.57, 1\n",
    "\n",
    "dur_f = 5\n",
    "win_len = tce[\"tce_duration\"].values[0] / 24 * dur_f\n",
    "\n",
    "t_start, t_end = t0 - win_len / 2, t0 + win_len / 2\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "lcf.plot(ax=ax)\n",
    "ax.set_xlim([t_start, t_end])\n",
    "ax.set_title(f\"TCE {tce_uid} | Disposition {disp_tce}\\nt0={t0} | Label {win_label}\")\n",
    "f.savefig(plot_dir / f\"plot_{tce_uid}_{disp_tce}_timestamp{t0}_label{win_label}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrec_fp = Path(\"/Users/jochoa4/Desktop/study_transfers/study_model_preds_05-22-2025/tfrecords/norm_train_shard_2990-8611.tfrecord\")\n",
    "\n",
    "\n",
    "t0, win_label = 1966.07, 0  # 2425.47, 0  # 2424.57, 1\n",
    "\n",
    "dur_f = 5\n",
    "win_len = tce[\"tce_duration\"].values[0] / 24 * dur_f\n",
    "\n",
    "t_start, t_end = t0 - win_len / 2, t0 + win_len / 2\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "lcf.plot(ax=ax)\n",
    "ax.set_xlim([t_start, t_end])\n",
    "ax.set_title(f\"TCE {tce_uid} | Disposition {disp_tce}\\nt0={t0} | Label {win_label}\")\n",
    "f.savefig(plot_dir / f\"plot_{tce_uid}_{disp_tce}_timestamp{t0}_label{win_label}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tce_uid = \"161687311-2-S24\"\n",
    "\n",
    "examples_tce = preds_tbl.loc[preds_tbl[\"tce_uid\"] == tce_uid]\n",
    "disp_tce = examples_tce[\"disposition\"].values[0]\n",
    "mes_tce = examples_tce[\"tce_max_mult_ev\"].values[0]\n",
    "\n",
    "transit_window_examples = examples_tce.loc[examples_tce[\"label\"] == 1]\n",
    "not_transit_window_examples = examples_tce.loc[examples_tce[\"label\"] == 0]\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.scatter(\n",
    "    transit_window_examples[\"time\"],\n",
    "    transit_window_examples[\"raw_pred\"],\n",
    "    s=8,\n",
    "    alpha=0.3,\n",
    "    edgecolors=\"k\",\n",
    "    label=\"Transit Window Examples\",\n",
    ")\n",
    "ax.scatter(\n",
    "    not_transit_window_examples[\"time\"],\n",
    "    not_transit_window_examples[\"raw_pred\"],\n",
    "    s=8,\n",
    "    alpha=0.3,\n",
    "    edgecolors=\"k\",\n",
    "    label=\"Not-Transit Window Examples\",\n",
    ")\n",
    "ax.set_ylabel(\"Model Score\")\n",
    "ax.set_xlabel(\"Timestamp [BTJD]\")\n",
    "ax.set_ylim(bins_scores[[0, -1]])\n",
    "ax.legend()\n",
    "ax.set_title(\n",
    "    f\"TCE {tce_uid}\\nDisposition {disp_tce}\\nNumber of examples\"\n",
    "    f\" {len(examples_tce)} | TCE Max MES {mes_tce:.3f}\"\n",
    ")\n",
    "f.tight_layout()\n",
    "f.savefig(\n",
    "    plot_dir / f\"scatter_transit_nottransit_examples_scores_{tce_uid}_{disp_tce}.png\"\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "bins_scores = np.linspace(0, 1, 11)\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "ax.hist(\n",
    "    transit_window_examples[\"raw_pred\"],\n",
    "    bins_scores,\n",
    "    histtype=\"step\",\n",
    "    label=\"Transit Window Examples\",\n",
    ")\n",
    "ax.hist(\n",
    "    not_transit_window_examples[\"raw_pred\"],\n",
    "    bins_scores,\n",
    "    histtype=\"step\",\n",
    "    label=\"Not-Transit Window Examples\",\n",
    ")\n",
    "ax.set_xlabel(\"Model Score\")\n",
    "ax.set_ylabel(\"Example Count\")\n",
    "ax.set_xlim(bins_scores[[0, -1]])\n",
    "ax.legend()\n",
    "ax.set_title(\n",
    "    f\"TCE {tce_uid}\\nDisposition {disp_tce}\\nNumber of examples\"\n",
    "    f\" {len(examples_tce)} | TCE Max MES {mes_tce:.3f}\"\n",
    ")\n",
    "f.tight_layout()\n",
    "f.savefig(\n",
    "    plot_dir / f\"hist_transit_nottransit_examples_scores_{tce_uid}_{disp_tce}.png\"\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tce_uid =  \"161687311-2-S24\" #\"352954787-1-S14-26\"  # \"198408416-1-S14-60\"  # '425064757-1-S1-65'   # '198408416-1-S14-60'\n",
    "lc_dir = Path(\"/Users/jochoa4/Downloads/\")\n",
    "sector_arr = list(range(24, 25))\n",
    "\n",
    "\n",
    "tce = tce_tbl.loc[tce_tbl[\"tce_uid\"] == tce_uid]\n",
    "\n",
    "# find light curve data for target\n",
    "search_lc_res = lk.search_lightcurve(\n",
    "    target=f\"tic{tce['target_id'].values[0]}\",\n",
    "    mission=\"TESS\",\n",
    "    author=(\"TESS-SPOC\", \"SPOC\"),\n",
    "    exptime=120,\n",
    "    cadence=\"long\",\n",
    "    sector=sector_arr,\n",
    ")\n",
    "\n",
    "lcf = search_lc_res.download_all(\n",
    "    download_dir=str(lc_dir), quality_bitmask=\"default\", flux_column=\"pdcsap_flux\"\n",
    ")\n",
    "\n",
    "\n",
    "def lcf_masked_quantity_corrector(lcf: lk.LightCurve) -> lk.LightCurve:\n",
    "    lcf = lk.LightCurve({\"time\": lcf.time.value, \"flux\": np.array(lcf.flux.value)})\n",
    "    return lcf.normalize()\n",
    "\n",
    "\n",
    "lcf = lcf.stitch(corrector_func=lcf_masked_quantity_corrector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t0, win_label = 1970.34, 1 #1696.34, 0  # 2425.47, 0  # 2424.57, 1\n",
    "\n",
    "dur_f = 5\n",
    "win_len = tce[\"tce_duration\"].values[0] / 24 * dur_f\n",
    "\n",
    "t_start, t_end = t0 - win_len / 2, t0 + win_len / 2\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "lcf.plot(ax=ax)\n",
    "ax.set_xlim([t_start, t_end])\n",
    "ax.set_title(f\"TCE {tce_uid} | Disposition {disp_tce}\\nt0={t0} | Label {win_label}\")\n",
    "f.savefig(plot_dir / f\"plot_{tce_uid}_{disp_tce}_timestamp{t0}_label{win_label}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exoplnt_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
